{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "from tqdm import trange\n",
    "from scipy.stats import pointbiserialr\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_raw = pd.read_csv('../Data/UNSW-NB15/train.csv')\n",
    "display(train_raw.shape)\n",
    "test_raw = pd.read_csv('../Data/UNSW-NB15/test.csv')\n",
    "display(test_raw.shape)\n",
    "\n",
    "# Seperate label and Drop ID\n",
    "train_X = train_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "train_Y = train_raw['label']\n",
    "test_X = test_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "test_Y = test_raw['label']\n",
    "\n",
    "# Normalize data with min, max of training data\n",
    "test_X1 = (test_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "train_X1 = (train_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "\n",
    "test_X1[test_X1 < 0] = 0\n",
    "test_X1[test_X1 > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation based feature selection\n",
    "corr = train_X1.corr().abs()\n",
    "\n",
    "threshold = 0.8\n",
    "corr.values[np.tril_indices_from(corr.values)] = np.nan\n",
    "redundant = []\n",
    "for j in corr.columns:\n",
    "    for i in corr.index:\n",
    "        if corr.loc[i, j] > threshold:\n",
    "            redundant.append((i, j))\n",
    "\n",
    "train_X2 = train_X1.copy()\n",
    "train_X2['label'] = train_Y\n",
    "corr2 = train_X2.corr().abs()\n",
    "\n",
    "corr3 = corr2['label'].iloc[:-1].copy()\n",
    "drop = []\n",
    "\n",
    "for i, j in redundant:\n",
    "    if corr3[i] > corr3[j] and j not in drop:\n",
    "        drop.append(j)\n",
    "    elif i not in drop:\n",
    "        drop.append(i)\n",
    "print(drop)\n",
    "\n",
    "train_X1 = train_X1.drop(drop, axis=1)\n",
    "test_X1 = test_X1.drop(drop, axis=1)\n",
    "print(train_X1.shape)\n",
    "print(test_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFECV, SequentialFeatureSelector, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy search\n",
    "greedy_all = []\n",
    "clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "model = LogisticRegression(max_iter=10000, random_state=0, n_jobs=-1)\n",
    "for k in trange(train_X1.shape[1]-1):\n",
    "    features = []\n",
    "    scores = []\n",
    "    selector = SelectKBest(mutual_info_classif, k='all')\n",
    "    # select one best feature and add it to subset\n",
    "    selector.fit(train_X1.drop(greedy_all, axis=1), train_Y)\n",
    "    f = train_X1.columns.drop(greedy_all)[np.argsort(selector.scores_)[0]]\n",
    "    features.append(f)\n",
    "    cv = cross_val_score(model, train_X1.drop(greedy_all+[f], axis=1), train_Y, scoring='f1', n_jobs=-1)\n",
    "    scores.append(cv.mean())\n",
    "\n",
    "    selector = SequentialFeatureSelector(clf, n_features_to_select=1, direction='backward', scoring='f1', cv=5, n_jobs=-1)\n",
    "    # select one best feature and add it to subset\n",
    "    selector.fit(train_X1.drop(greedy_all, axis=1), train_Y)\n",
    "    f = train_X1.columns.drop(greedy_all)[selector.get_support()]\n",
    "    features.append(f[0])\n",
    "    cv = cross_val_score(model, train_X1.drop(greedy_all+f, axis=1), train_Y, scoring='f1', n_jobs=-1)\n",
    "    scores.append(cv.mean())\n",
    "\n",
    "    selector = RFECV(clf, min_features_to_select=train_X1.shape[1], scoring='f1', cv=5, n_jobs=-1)\n",
    "    selector.fit(train_X1, train_Y)\n",
    "    f = train_X1.columns.drop(greedy_all)[np.argsort(selector.cv_results_.mean_test_score)[0]]\n",
    "    features.append(f)\n",
    "    cv = cross_val_score(model, train_X1.drop(greedy_all+[f], axis=1), train_Y, scoring='f1', n_jobs=-1)\n",
    "    scores.append(cv.mean())\n",
    "\n",
    "    i_best = np.argmax(scores)\n",
    "    greedy_all.append(features[i_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with LR\n",
    "cv_times_all = []\n",
    "f1_all = []\n",
    "model = LogisticRegression(max_iter=10000, random_state=0, n_jobs=-1)\n",
    "for k in trange(train_X1.shape[1]):\n",
    "    # cross validation\n",
    "    second = time.time()\n",
    "    cv = cross_val_score(model, train_X1[greedy_all[k:]], train_Y, scoring='f1', n_jobs=-1)\n",
    "    second2 = time.time()\n",
    "    cv_times_all.append(second2 - second)\n",
    "    f1_all.append((cv.mean(), cv.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all[::-1], index=['greedy']).to_csv('../Results/Paper/Greedy_Time_LR.csv')\n",
    "pd.DataFrame(f1_all[::-1], index=['greedy']).to_csv('../Results/Paper/Greedy_F1_LR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Logistic Regression', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[:,0], color='blue', linestyle='-', label='greedy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all, color='blue', linestyle='-', label='greedy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with GB\n",
    "cv_times_all = []\n",
    "f1_all = []\n",
    "model = GradientBoostingClassifier(random_state=0)\n",
    "for k in trange(train_X1.shape[1]):\n",
    "    # cross validation\n",
    "    second = time.time()\n",
    "    cv = cross_val_score(model, train_X1[greedy_all[k:]], train_Y, scoring='f1', n_jobs=-1)\n",
    "    second2 = time.time()\n",
    "    cv_times_all.append(second2 - second)\n",
    "    f1_all.append((cv.mean(), cv.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all[::-1], index=['greedy']).to_csv('../Results/Paper/Greedy_Time_GB.csv')\n",
    "pd.DataFrame(f1_all[::-1], index=['greedy']).to_csv('../Results/Paper/Greedy_F1_GB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Gradient Boosting', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[:,0], color='blue', linestyle='-', label='greedy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all, color='blue', linestyle='-', label='greedy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, layers, losses, metrics, callbacks\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCreate(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "kf = StratifiedKFold(shuffle=True, random_state=0)\n",
    "callback = callbacks.EarlyStopping(patience=3, min_delta=0.1, restore_best_weights=True)\n",
    "for k in trange(train_X1.shape[1]):\n",
    "    model = ModelCreate((train_X1.shape[1]-k,))\n",
    "    # cross validation\n",
    "    j = 0\n",
    "    cv_time = 0\n",
    "    cv = np.zeros(shape=5)\n",
    "    train_X2 = train_X1[greedy_all[k:]].copy()\n",
    "    for train_index, test_index in kf.split(train_X2, train_Y):\n",
    "        x_train_fold, x_test_fold = train_X2.iloc[train_index, :], train_X2.iloc[test_index, :]\n",
    "        y_train_fold, y_test_fold = train_Y.iloc[train_index], train_Y.iloc[test_index]\n",
    "\n",
    "        second = time.time()\n",
    "        model.fit(x_train_fold.values, y_train_fold.values, validation_data=(x_test_fold, y_test_fold), epochs=30, callbacks=[callback], verbose=0)\n",
    "        predict = model.predict(x_test_fold, use_multiprocessing=True)\n",
    "        predict = np.where(predict < 0.5, 0, 1)\n",
    "        cv[j] = f1_score(y_test_fold, predict)\n",
    "        second2 = time.time()\n",
    "        cv_time += second2 - second\n",
    "        j += 1\n",
    "    cv_times_all.append(cv_time)\n",
    "    f1_all.append((cv.mean(), cv.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all[::-1], index=['greedy']).to_csv('../Results/Paper/Greedy_Time_DNN.csv')\n",
    "pd.DataFrame(f1_all[::-1], index=['greedy']).to_csv('../Results/Paper/Greedy_F1_DNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Deep Neuron Network', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[:,0], color='blue', linestyle='-', label='greedy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all, color='blue', linestyle='-', label='greedy')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c4f194b091935ea0535537ef7f3ca3b8fc985a0d71c01646ea70346d6ccae7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
