{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "from tqdm import trange\n",
    "from scipy.stats import pointbiserialr\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_raw = pd.read_csv('../Data/UNSW-NB15/train.csv')\n",
    "print(train_raw.shape)\n",
    "test_raw = pd.read_csv('../Data/UNSW-NB15/test.csv')\n",
    "print(test_raw.shape)\n",
    "\n",
    "# Seperate label and Drop ID\n",
    "train_X = train_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "train_Y = train_raw['label']\n",
    "test_X = test_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "test_Y = test_raw['label']\n",
    "\n",
    "# Normalize data with min, max of training data\n",
    "test_X1 = (test_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "train_X1 = (train_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "\n",
    "test_X1[test_X1 < 0] = 0\n",
    "test_X1[test_X1 > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation based feature selection\n",
    "corr = train_X1.corr().abs()\n",
    "\n",
    "threshold = 0.8\n",
    "corr.values[np.tril_indices_from(corr.values)] = np.nan\n",
    "redundant = []\n",
    "for j in corr.columns:\n",
    "    for i in corr.index:\n",
    "        if corr.loc[i, j] > threshold:\n",
    "            redundant.append((i, j))\n",
    "\n",
    "train_X2 = train_X1.copy()\n",
    "train_X2['label'] = train_Y\n",
    "corr2 = train_X2.corr().abs()\n",
    "\n",
    "corr3 = corr2['label'].iloc[:-1].copy()\n",
    "drop = []\n",
    "\n",
    "for i, j in redundant:\n",
    "    if corr3[i] > corr3[j] and j not in drop:\n",
    "        drop.append(j)\n",
    "    elif i not in drop:\n",
    "        drop.append(i)\n",
    "print(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = train_X1.drop(drop, axis=1)\n",
    "test_X1 = test_X1.drop(drop, axis=1)\n",
    "print(train_X1.shape)\n",
    "print(test_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_all = pd.read_csv('../Results/Paper/Feature_sets.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_all = []\n",
    "intersection_all = []\n",
    "qourum_all = []\n",
    "\n",
    "for k in trange(train_X1.shape[1]):\n",
    "    unions = []\n",
    "    intersections = []\n",
    "    qourums = []\n",
    "    for c in train_X1.columns:\n",
    "        candidates = subset_all[:, k:]\n",
    "        count = np.count_nonzero(candidates == c)\n",
    "        if count > 0:\n",
    "            unions.append(c)\n",
    "        if count > len(subset_all) / 2:\n",
    "            qourums.append(c)\n",
    "        if count == len(subset_all):\n",
    "            intersections.append(c)\n",
    "    union_all.append(unions)\n",
    "    intersection_all.append(intersections)\n",
    "    qourum_all.append(qourums)\n",
    "print(union_all)\n",
    "print(intersection_all)\n",
    "print(qourum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "model = LogisticRegression(max_iter=10000, random_state=0, n_jobs=-1)\n",
    "for all in [union_all, intersection_all, qourum_all]:\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        # cross validation\n",
    "        second = time.time()\n",
    "        cv = cross_val_score(model, train_X1[all[k:]], train_Y, scoring='f1', n_jobs=-1)\n",
    "        second2 = time.time()\n",
    "        cv_times.append(second2 - second)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "\n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all[::-1], index=['union', 'intersection', 'quorum']).to_csv('../Data/Results/Set_Time_LR.csv')\n",
    "pd.DataFrame(f1_all[::-1], index=['union', 'intersection', 'quorum']).to_csv('../Data/Results/Set_F1_LR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Logistic Regression', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label='union')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[1,:,0], color='red', linestyle='-', label='intersection')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[2,:,0], color='black', linestyle='-', label='quorum')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[0], color='blue', linestyle='-', label='union')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[1], color='red', linestyle='-', label='intersection')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[2], color='black', linestyle='-', label='quorum')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "model = GradientBoostingClassifier(random_state=0)\n",
    "for all in [union_all, intersection_all, qourum_all]:\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        # cross validation\n",
    "        second = time.time()\n",
    "        cv = cross_val_score(model, train_X1[all[k:]], train_Y, scoring='f1', n_jobs=-1)\n",
    "        second2 = time.time()\n",
    "        cv_times.append(second2 - second)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "\n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all[::-1], index=['union', 'intersection', 'quorum']).to_csv('../Data/Results/Set_Time_GB.csv')\n",
    "pd.DataFrame(f1_all[::-1], index=['union', 'intersection', 'quorum']).to_csv('../Data/Results/Set_F1_GB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Gradient Boosting', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label='union')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[1,:,0], color='red', linestyle='-', label='intersection')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[2,:,0], color='black', linestyle='-', label='quorum')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[0], color='blue', linestyle='-', label='union')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[1], color='red', linestyle='-', label='intersection')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[2], color='black', linestyle='-', label='quorum')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, layers, losses, metrics, callbacks\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCreate(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "kf = StratifiedKFold(shuffle=True, random_state=0)\n",
    "callback = callbacks.EarlyStopping(patience=3, min_delta=0.1, restore_best_weights=True)\n",
    "for all in [union_all, intersection_all, qourum_all]:\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        model = ModelCreate((train_X1.shape[1]-k,))\n",
    "        # cross validation\n",
    "        j = 0\n",
    "        cv_time = 0\n",
    "        cv = np.zeros(shape=5)\n",
    "        train_X2 = train_X1[all[k:]].copy()\n",
    "        for train_index, test_index in kf.split(train_X2, train_Y):\n",
    "            x_train_fold, x_test_fold = train_X2.iloc[train_index, :], train_X2.iloc[test_index, :]\n",
    "            y_train_fold, y_test_fold = train_Y.iloc[train_index], train_Y.iloc[test_index]\n",
    "\n",
    "            second = time.time()\n",
    "            model.fit(x_train_fold.values, y_train_fold.values, validation_data=(x_test_fold, y_test_fold), epochs=30, callbacks=[callback], verbose=0)\n",
    "            predict = model.predict(x_test_fold, use_multiprocessing=True)\n",
    "            predict = np.where(predict < 0.5, 0, 1)\n",
    "            cv[j] = f1_score(y_test_fold, predict)\n",
    "            second2 = time.time()\n",
    "            cv_time += second2 - second\n",
    "            j += 1\n",
    "        cv_times.append(cv_time)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "    \n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all[::-1], index=['union', 'intersection', 'quorum']).to_csv('../Data/Results/Set_Time_DNN.csv')\n",
    "pd.DataFrame(f1_all[::-1], index=['union', 'intersection', 'quorum']).to_csv('../Data/Results/Set_F1_DNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Gradient Boosting', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label='union')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[1,:,0], color='red', linestyle='-', label='intersection')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[2,:,0], color='black', linestyle='-', label='quorum')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[0], color='blue', linestyle='-', label='union')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[1], color='red', linestyle='-', label='intersection')\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[2], color='black', linestyle='-', label='quorum')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c4f194b091935ea0535537ef7f3ca3b8fc985a0d71c01646ea70346d6ccae7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
