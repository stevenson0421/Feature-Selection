{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494021, 42)\n",
      "(311029, 42)\n",
      "(494021, 38)\n",
      "(311029, 38)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_raw = pd.read_csv('../Data/KDDCUP99/train.csv')\n",
    "test_raw = pd.read_csv('../Data/KDDCUP99/test.csv')\n",
    "print(train_raw.shape)\n",
    "print(test_raw.shape)\n",
    "\n",
    "# Seperate label and Drop ID\n",
    "def LabelEncode(x):\n",
    "    if x == 'normal.':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "train_X = train_raw.drop(['type'], axis=1).select_dtypes(include='number')\n",
    "print(train_X.shape)\n",
    "test_X = test_raw.drop(['type'], axis=1).select_dtypes(include='number')\n",
    "print(test_X.shape)\n",
    "train_Y = train_raw['type'].apply(LabelEncode)\n",
    "test_Y = test_raw['type'].apply(LabelEncode)\n",
    "\n",
    "# Normalize data with min, max of training data\n",
    "test_X1 = (test_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "train_X1 = (train_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "\n",
    "test_X1[test_X1 < 0] = 0\n",
    "test_X1[test_X1 > 1] = 1\n",
    "\n",
    "train_X1.fillna(0, inplace=True)\n",
    "test_X1.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lr = ['count', 'logged_in']\n",
    "features_gb = ['count', 'logged_in', 'dst_bytes']\n",
    "features_nn = ['count', 'logged_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccis229c\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.997867 using {'C': 100, 'max_iter': 100, 'solver': 'liblinear'} with all features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccis229c\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.988097 using {'C': 0.01, 'max_iter': 100, 'solver': 'liblinear'} with selected features\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters to search\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "max_iter = [100, 300, 500, 1000, 5000, 10000]\n",
    "grid = dict(solver=solvers, C=c_values, max_iter=max_iter)\n",
    "# grid search\n",
    "model_lr = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "cv = RepeatedStratifiedKFold(random_state=0)\n",
    "grid_search = GridSearchCV(estimator=model_lr, param_grid=grid, scoring='f1', cv=cv, n_jobs=-1, error_score=0)\n",
    "grid_result = grid_search.fit(train_X1, train_Y)\n",
    "# get the best result\n",
    "print(\"Best: %f using %s with all features\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "grid_result = grid_search.fit(train_X1[features_lr], train_Y)\n",
    "# get the best result\n",
    "print(\"Best: %f using %s with selected features\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9481575374987187\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(solver='liblinear', C=100, max_iter=100, random_state=0)\n",
    "model_lr.fit(train_X1, train_Y)\n",
    "predict = model_lr.predict(test_X1)\n",
    "print(f1_score(test_Y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccis229c\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9412706012801775\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(solver='liblinear', C=0.01, max_iter=100, n_jobs=-1, random_state=0)\n",
    "model_lr.fit(train_X1[features_lr], train_Y)\n",
    "predict = model_lr.predict(test_X1[features_lr])\n",
    "print(f1_score(test_Y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters to search\n",
    "n_estimators = [1000, 3000, 5000, 10000]\n",
    "learning_rate = [0.01, 0.1]\n",
    "subsample = [0.7, 0.8, 0.9, 1.0]\n",
    "max_depth = [7, 9, 11]\n",
    "grid = dict(n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, max_depth=max_depth)\n",
    "\n",
    "model_gb = GradientBoostingClassifier(random_state=0)\n",
    "grid_search = GridSearchCV(estimator=model_gb, param_grid=grid, scoring='f1', cv=cv, n_jobs=-1, error_score=0)\n",
    "grid_result = grid_search.fit(train_X1, train_Y)\n",
    "# get the best result\n",
    "print(\"Best: %f using %s with all features\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "grid_result = grid_search.fit(train_X1[features_gb], train_Y)\n",
    "# get the best result\n",
    "print(\"Best: %f using %s with selected features\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9459537560150266\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingClassifier(learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0, random_state=0)\n",
    "model_gb.fit(train_X1[features_gb], train_Y)\n",
    "predict = model_gb.predict(test_X1[features_gb])\n",
    "print(f1_score(test_Y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952293604815139\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingClassifier(learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.7, random_state=0)\n",
    "model_gb.fit(train_X1, train_Y)\n",
    "predict = model_gb.predict(test_X1)\n",
    "print(f1_score(test_Y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential, layers, optimizers, losses, metrics, callbacks, backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCreate(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "386/386 [==============================] - 3s 5ms/step - loss: 0.1106 - binary_accuracy: 0.9645 - val_loss: 0.0435 - val_binary_accuracy: 0.9925\n",
      "Epoch 2/1000\n",
      "386/386 [==============================] - 2s 4ms/step - loss: 0.0731 - binary_accuracy: 0.9788 - val_loss: 0.0451 - val_binary_accuracy: 0.9923\n",
      "Epoch 3/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0721 - binary_accuracy: 0.9792 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 4/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0715 - binary_accuracy: 0.9792 - val_loss: 0.0417 - val_binary_accuracy: 0.9925\n",
      "Epoch 5/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0709 - binary_accuracy: 0.9793 - val_loss: 0.0436 - val_binary_accuracy: 0.9923\n",
      "Epoch 6/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0700 - binary_accuracy: 0.9794 - val_loss: 0.0436 - val_binary_accuracy: 0.9923\n",
      "Epoch 7/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0695 - binary_accuracy: 0.9794 - val_loss: 0.0431 - val_binary_accuracy: 0.9923\n",
      "Epoch 8/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0690 - binary_accuracy: 0.9794 - val_loss: 0.0444 - val_binary_accuracy: 0.9923\n",
      "Epoch 9/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0684 - binary_accuracy: 0.9794 - val_loss: 0.0424 - val_binary_accuracy: 0.9920\n",
      "Epoch 10/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0677 - binary_accuracy: 0.9793 - val_loss: 0.0420 - val_binary_accuracy: 0.9923\n",
      "Epoch 11/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0672 - binary_accuracy: 0.9793 - val_loss: 0.0464 - val_binary_accuracy: 0.9921\n",
      "Epoch 12/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0665 - binary_accuracy: 0.9794 - val_loss: 0.0425 - val_binary_accuracy: 0.9921\n",
      "Epoch 13/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0662 - binary_accuracy: 0.9794 - val_loss: 0.0446 - val_binary_accuracy: 0.9923\n",
      "Epoch 14/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0661 - binary_accuracy: 0.9794 - val_loss: 0.0418 - val_binary_accuracy: 0.9922\n",
      "Epoch 15/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0659 - binary_accuracy: 0.9794 - val_loss: 0.0423 - val_binary_accuracy: 0.9922\n",
      "Epoch 16/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0659 - binary_accuracy: 0.9795 - val_loss: 0.0419 - val_binary_accuracy: 0.9923\n",
      "Epoch 17/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0657 - binary_accuracy: 0.9794 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 18/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0656 - binary_accuracy: 0.9794 - val_loss: 0.0417 - val_binary_accuracy: 0.9924\n",
      "Epoch 19/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0656 - binary_accuracy: 0.9794 - val_loss: 0.0457 - val_binary_accuracy: 0.9918\n",
      "Epoch 20/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0655 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9920\n",
      "Epoch 21/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0654 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 22/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0654 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 23/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0652 - binary_accuracy: 0.9795 - val_loss: 0.0432 - val_binary_accuracy: 0.9923\n",
      "Epoch 24/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0652 - binary_accuracy: 0.9795 - val_loss: 0.0407 - val_binary_accuracy: 0.9923\n",
      "Epoch 25/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0654 - binary_accuracy: 0.9794 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 26/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0650 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9922\n",
      "Epoch 27/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0651 - binary_accuracy: 0.9794 - val_loss: 0.0409 - val_binary_accuracy: 0.9920\n",
      "Epoch 28/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0653 - binary_accuracy: 0.9794 - val_loss: 0.0423 - val_binary_accuracy: 0.9922\n",
      "Epoch 29/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0651 - binary_accuracy: 0.9795 - val_loss: 0.0424 - val_binary_accuracy: 0.9923\n",
      "Epoch 30/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0649 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 31/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0650 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9924\n",
      "Epoch 32/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0650 - binary_accuracy: 0.9795 - val_loss: 0.0424 - val_binary_accuracy: 0.9923\n",
      "Epoch 33/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0649 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9923\n",
      "Epoch 34/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0649 - binary_accuracy: 0.9794 - val_loss: 0.0421 - val_binary_accuracy: 0.9923\n",
      "Epoch 35/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0649 - binary_accuracy: 0.9794 - val_loss: 0.0429 - val_binary_accuracy: 0.9924\n",
      "Epoch 36/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0649 - binary_accuracy: 0.9795 - val_loss: 0.0423 - val_binary_accuracy: 0.9923\n",
      "Epoch 37/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0650 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9923\n",
      "Epoch 38/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0648 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9923\n",
      "Epoch 39/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0647 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9923\n",
      "Epoch 40/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 41/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0648 - binary_accuracy: 0.9795 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 42/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0647 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 43/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0649 - binary_accuracy: 0.9796 - val_loss: 0.0425 - val_binary_accuracy: 0.9924\n",
      "Epoch 44/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 45/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0648 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9923\n",
      "Epoch 46/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 47/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0409 - val_binary_accuracy: 0.9922\n",
      "Epoch 48/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0648 - binary_accuracy: 0.9795 - val_loss: 0.0426 - val_binary_accuracy: 0.9923\n",
      "Epoch 49/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9796 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 50/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0647 - binary_accuracy: 0.9795 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 51/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 52/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9923\n",
      "Epoch 53/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 54/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9795 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 55/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9796 - val_loss: 0.0427 - val_binary_accuracy: 0.9923\n",
      "Epoch 56/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9795 - val_loss: 0.0414 - val_binary_accuracy: 0.9922\n",
      "Epoch 57/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0420 - val_binary_accuracy: 0.9923\n",
      "Epoch 58/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9923\n",
      "Epoch 59/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0407 - val_binary_accuracy: 0.9922\n",
      "Epoch 60/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 61/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9795 - val_loss: 0.0420 - val_binary_accuracy: 0.9923\n",
      "Epoch 62/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0419 - val_binary_accuracy: 0.9923\n",
      "Epoch 63/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9795 - val_loss: 0.0426 - val_binary_accuracy: 0.9923\n",
      "Epoch 64/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0421 - val_binary_accuracy: 0.9923\n",
      "Epoch 65/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 66/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9796 - val_loss: 0.0413 - val_binary_accuracy: 0.9923\n",
      "Epoch 67/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9796 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 68/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 69/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0419 - val_binary_accuracy: 0.9923\n",
      "Epoch 70/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0646 - binary_accuracy: 0.9795 - val_loss: 0.0440 - val_binary_accuracy: 0.9923\n",
      "Epoch 71/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9796 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 72/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 73/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0645 - binary_accuracy: 0.9795 - val_loss: 0.0419 - val_binary_accuracy: 0.9923\n",
      "Epoch 74/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9923\n",
      "Epoch 75/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9796 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 76/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 77/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 78/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 79/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0454 - val_binary_accuracy: 0.9922\n",
      "Epoch 80/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9922\n",
      "Epoch 81/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 82/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 83/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0431 - val_binary_accuracy: 0.9923\n",
      "Epoch 84/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0423 - val_binary_accuracy: 0.9922\n",
      "Epoch 85/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 86/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 87/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0420 - val_binary_accuracy: 0.9922\n",
      "Epoch 88/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 89/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 90/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 91/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9796 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 92/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 93/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9796 - val_loss: 0.0416 - val_binary_accuracy: 0.9923\n",
      "Epoch 94/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 95/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 96/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 97/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9796 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 98/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0417 - val_binary_accuracy: 0.9922\n",
      "Epoch 99/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9923\n",
      "Epoch 100/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 101/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 102/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 103/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 104/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 105/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 106/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 107/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 108/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 109/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 110/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 111/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 112/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0445 - val_binary_accuracy: 0.9923\n",
      "Epoch 113/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0423 - val_binary_accuracy: 0.9922\n",
      "Epoch 114/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9923\n",
      "Epoch 115/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9923\n",
      "Epoch 116/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0424 - val_binary_accuracy: 0.9923\n",
      "Epoch 117/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 118/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 119/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0420 - val_binary_accuracy: 0.9923\n",
      "Epoch 120/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0420 - val_binary_accuracy: 0.9921\n",
      "Epoch 121/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9921\n",
      "Epoch 122/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0412 - val_binary_accuracy: 0.9923\n",
      "Epoch 123/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 124/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 125/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 126/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 127/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9922\n",
      "Epoch 128/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 129/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0422 - val_binary_accuracy: 0.9922\n",
      "Epoch 130/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0413 - val_binary_accuracy: 0.9922\n",
      "Epoch 131/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 132/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 133/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9922\n",
      "Epoch 134/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9923\n",
      "Epoch 135/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 136/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0412 - val_binary_accuracy: 0.9921\n",
      "Epoch 137/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 138/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 139/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 140/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0418 - val_binary_accuracy: 0.9922\n",
      "Epoch 141/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0419 - val_binary_accuracy: 0.9923\n",
      "Epoch 142/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9923\n",
      "Epoch 143/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 144/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 145/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 146/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 147/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 148/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 149/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 150/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0643 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9921\n",
      "Epoch 151/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 152/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 153/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9796 - val_loss: 0.0420 - val_binary_accuracy: 0.9922\n",
      "Epoch 154/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9923\n",
      "Epoch 155/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 156/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 157/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0421 - val_binary_accuracy: 0.9922\n",
      "Epoch 158/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 159/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 160/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 161/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0414 - val_binary_accuracy: 0.9923\n",
      "Epoch 162/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9923\n",
      "Epoch 163/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0446 - val_binary_accuracy: 0.9922\n",
      "Epoch 164/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9923\n",
      "Epoch 165/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0420 - val_binary_accuracy: 0.9922\n",
      "Epoch 166/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0423 - val_binary_accuracy: 0.9921\n",
      "Epoch 167/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 168/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 169/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 170/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 171/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0422 - val_binary_accuracy: 0.9922\n",
      "Epoch 172/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 173/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0428 - val_binary_accuracy: 0.9923\n",
      "Epoch 174/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 175/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0447 - val_binary_accuracy: 0.9922\n",
      "Epoch 176/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 177/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 178/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9923\n",
      "Epoch 179/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0426 - val_binary_accuracy: 0.9923\n",
      "Epoch 180/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 181/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 182/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 183/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 184/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 185/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 186/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0422 - val_binary_accuracy: 0.9922\n",
      "Epoch 187/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 188/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 189/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9923\n",
      "Epoch 190/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0450 - val_binary_accuracy: 0.9922\n",
      "Epoch 191/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 192/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9923\n",
      "Epoch 193/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 194/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 195/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 196/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 197/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 198/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 199/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 200/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 201/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 202/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 203/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 204/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9796 - val_loss: 0.0428 - val_binary_accuracy: 0.9923\n",
      "Epoch 205/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 206/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 207/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0443 - val_binary_accuracy: 0.9923\n",
      "Epoch 208/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 209/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 210/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9923\n",
      "Epoch 211/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0404 - val_binary_accuracy: 0.9923\n",
      "Epoch 212/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 213/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0420 - val_binary_accuracy: 0.9922\n",
      "Epoch 214/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0429 - val_binary_accuracy: 0.9923\n",
      "Epoch 215/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 216/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0424 - val_binary_accuracy: 0.9922\n",
      "Epoch 217/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 218/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9796 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 219/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 220/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 221/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 222/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 223/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 224/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 225/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 226/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9923\n",
      "Epoch 227/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 228/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 229/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 230/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 231/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 232/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 233/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 234/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 235/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 236/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9923\n",
      "Epoch 237/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0420 - val_binary_accuracy: 0.9922\n",
      "Epoch 238/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 239/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 240/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 241/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 242/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 243/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0423 - val_binary_accuracy: 0.9922\n",
      "Epoch 244/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 245/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0430 - val_binary_accuracy: 0.9923\n",
      "Epoch 246/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 247/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 248/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0641 - binary_accuracy: 0.9795 - val_loss: 0.0423 - val_binary_accuracy: 0.9922\n",
      "Epoch 249/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 250/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 251/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 252/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 253/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 254/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 255/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 256/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 257/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 258/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9923\n",
      "Epoch 259/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 260/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 261/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0423 - val_binary_accuracy: 0.9922\n",
      "Epoch 262/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 263/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9923\n",
      "Epoch 264/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0444 - val_binary_accuracy: 0.9923\n",
      "Epoch 265/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 266/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9923\n",
      "Epoch 267/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9923\n",
      "Epoch 268/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 269/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 270/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0424 - val_binary_accuracy: 0.9922\n",
      "Epoch 271/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 272/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 273/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0431 - val_binary_accuracy: 0.9922\n",
      "Epoch 274/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0421 - val_binary_accuracy: 0.9922\n",
      "Epoch 275/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 276/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 277/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9923\n",
      "Epoch 278/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9922\n",
      "Epoch 279/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9922\n",
      "Epoch 280/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 281/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 282/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 283/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 284/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 285/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 286/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9923\n",
      "Epoch 287/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 288/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 289/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 290/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0425 - val_binary_accuracy: 0.9923\n",
      "Epoch 291/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 292/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0430 - val_binary_accuracy: 0.9922\n",
      "Epoch 293/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 294/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 295/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 296/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 297/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 298/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 299/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0450 - val_binary_accuracy: 0.9922\n",
      "Epoch 300/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 301/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 302/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 303/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 304/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 305/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 306/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0452 - val_binary_accuracy: 0.9922\n",
      "Epoch 307/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 308/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0425 - val_binary_accuracy: 0.9922\n",
      "Epoch 309/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 310/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0431 - val_binary_accuracy: 0.9922\n",
      "Epoch 311/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 312/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 313/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 314/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 315/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0432 - val_binary_accuracy: 0.9922\n",
      "Epoch 316/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 317/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 318/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 319/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 320/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 321/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 322/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0448 - val_binary_accuracy: 0.9922\n",
      "Epoch 323/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 324/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 325/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 326/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 327/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0439 - val_binary_accuracy: 0.9922\n",
      "Epoch 328/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0429 - val_binary_accuracy: 0.9923\n",
      "Epoch 329/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 330/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 331/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 332/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 333/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 334/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 335/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0446 - val_binary_accuracy: 0.9923\n",
      "Epoch 336/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0454 - val_binary_accuracy: 0.9922\n",
      "Epoch 337/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 338/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 339/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0433 - val_binary_accuracy: 0.9922\n",
      "Epoch 340/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 341/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0462 - val_binary_accuracy: 0.9922\n",
      "Epoch 342/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 343/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0454 - val_binary_accuracy: 0.9922\n",
      "Epoch 344/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 345/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 346/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0430 - val_binary_accuracy: 0.9923\n",
      "Epoch 347/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 348/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 349/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 350/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 351/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0452 - val_binary_accuracy: 0.9922\n",
      "Epoch 352/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 353/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 354/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 355/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 356/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0461 - val_binary_accuracy: 0.9922\n",
      "Epoch 357/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 358/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 359/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 360/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 361/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 362/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9923\n",
      "Epoch 363/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 364/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 365/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 366/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0450 - val_binary_accuracy: 0.9922\n",
      "Epoch 367/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 368/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 369/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0427 - val_binary_accuracy: 0.9922\n",
      "Epoch 370/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 371/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 372/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 373/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 374/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0446 - val_binary_accuracy: 0.9923\n",
      "Epoch 375/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 376/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0447 - val_binary_accuracy: 0.9922\n",
      "Epoch 377/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 378/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0454 - val_binary_accuracy: 0.9922\n",
      "Epoch 379/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 380/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 381/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 382/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0447 - val_binary_accuracy: 0.9922\n",
      "Epoch 383/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0443 - val_binary_accuracy: 0.9923\n",
      "Epoch 384/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0448 - val_binary_accuracy: 0.9922\n",
      "Epoch 385/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0411 - val_binary_accuracy: 0.9922\n",
      "Epoch 386/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 387/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0447 - val_binary_accuracy: 0.9922\n",
      "Epoch 388/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0454 - val_binary_accuracy: 0.9921\n",
      "Epoch 389/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 390/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0457 - val_binary_accuracy: 0.9922\n",
      "Epoch 391/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 392/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0447 - val_binary_accuracy: 0.9922\n",
      "Epoch 393/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0429 - val_binary_accuracy: 0.9922\n",
      "Epoch 394/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 395/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0450 - val_binary_accuracy: 0.9922\n",
      "Epoch 396/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 397/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0452 - val_binary_accuracy: 0.9922\n",
      "Epoch 398/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 399/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0428 - val_binary_accuracy: 0.9923\n",
      "Epoch 400/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 401/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0633 - binary_accuracy: 0.9796 - val_loss: 0.0447 - val_binary_accuracy: 0.9922\n",
      "Epoch 402/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0463 - val_binary_accuracy: 0.9923\n",
      "Epoch 403/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0442 - val_binary_accuracy: 0.9922\n",
      "Epoch 404/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0448 - val_binary_accuracy: 0.9922\n",
      "Epoch 405/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 406/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 407/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 408/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 409/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0426 - val_binary_accuracy: 0.9922\n",
      "Epoch 410/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 411/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0454 - val_binary_accuracy: 0.9922\n",
      "Epoch 412/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9923\n",
      "Epoch 413/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 414/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0454 - val_binary_accuracy: 0.9922\n",
      "Epoch 415/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 416/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 417/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 418/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0461 - val_binary_accuracy: 0.9922\n",
      "Epoch 419/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 420/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 421/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 422/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 423/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 424/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0435 - val_binary_accuracy: 0.9922\n",
      "Epoch 425/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0448 - val_binary_accuracy: 0.9922\n",
      "Epoch 426/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0448 - val_binary_accuracy: 0.9922\n",
      "Epoch 427/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 428/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 429/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 430/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0446 - val_binary_accuracy: 0.9922\n",
      "Epoch 431/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 432/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 433/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0436 - val_binary_accuracy: 0.9922\n",
      "Epoch 434/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0466 - val_binary_accuracy: 0.9922\n",
      "Epoch 435/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0461 - val_binary_accuracy: 0.9922\n",
      "Epoch 436/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 437/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 438/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 439/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0448 - val_binary_accuracy: 0.9923\n",
      "Epoch 440/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0461 - val_binary_accuracy: 0.9922\n",
      "Epoch 441/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 442/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 443/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 444/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 445/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0454 - val_binary_accuracy: 0.9922\n",
      "Epoch 446/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 447/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0454 - val_binary_accuracy: 0.9923\n",
      "Epoch 448/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 449/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 450/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0437 - val_binary_accuracy: 0.9922\n",
      "Epoch 451/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 452/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0466 - val_binary_accuracy: 0.9922\n",
      "Epoch 453/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 454/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 455/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 456/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0441 - val_binary_accuracy: 0.9922\n",
      "Epoch 457/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0452 - val_binary_accuracy: 0.9922\n",
      "Epoch 458/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 459/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 460/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0445 - val_binary_accuracy: 0.9923\n",
      "Epoch 461/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 462/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0461 - val_binary_accuracy: 0.9922\n",
      "Epoch 463/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 464/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0447 - val_binary_accuracy: 0.9922\n",
      "Epoch 465/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 466/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0474 - val_binary_accuracy: 0.9922\n",
      "Epoch 467/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0438 - val_binary_accuracy: 0.9922\n",
      "Epoch 468/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 469/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0462 - val_binary_accuracy: 0.9923\n",
      "Epoch 470/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0468 - val_binary_accuracy: 0.9922\n",
      "Epoch 471/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0457 - val_binary_accuracy: 0.9922\n",
      "Epoch 472/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 473/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0458 - val_binary_accuracy: 0.9922\n",
      "Epoch 474/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0463 - val_binary_accuracy: 0.9922\n",
      "Epoch 475/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 476/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 477/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 478/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 479/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 480/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 481/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0463 - val_binary_accuracy: 0.9922\n",
      "Epoch 482/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0444 - val_binary_accuracy: 0.9922\n",
      "Epoch 483/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 484/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 485/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 486/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 487/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0440 - val_binary_accuracy: 0.9922\n",
      "Epoch 488/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 489/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 490/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0473 - val_binary_accuracy: 0.9922\n",
      "Epoch 491/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 492/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 493/1000\n",
      "386/386 [==============================] - ETA: 0s - loss: 0.0633 - binary_accuracy: 0.979 - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 494/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0461 - val_binary_accuracy: 0.9922\n",
      "Epoch 495/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 496/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 497/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0468 - val_binary_accuracy: 0.9922\n",
      "Epoch 498/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0482 - val_binary_accuracy: 0.9922\n",
      "Epoch 499/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0475 - val_binary_accuracy: 0.9922\n",
      "Epoch 500/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 501/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 502/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 503/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0487 - val_binary_accuracy: 0.9922\n",
      "Epoch 504/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 505/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 506/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0452 - val_binary_accuracy: 0.9922\n",
      "Epoch 507/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0484 - val_binary_accuracy: 0.9923\n",
      "Epoch 508/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 509/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 510/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 511/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0468 - val_binary_accuracy: 0.9923\n",
      "Epoch 512/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0492 - val_binary_accuracy: 0.9922\n",
      "Epoch 513/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0470 - val_binary_accuracy: 0.9922\n",
      "Epoch 514/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 515/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0434 - val_binary_accuracy: 0.9922\n",
      "Epoch 516/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0456 - val_binary_accuracy: 0.9923\n",
      "Epoch 517/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0463 - val_binary_accuracy: 0.9922\n",
      "Epoch 518/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0484 - val_binary_accuracy: 0.9922\n",
      "Epoch 519/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0473 - val_binary_accuracy: 0.9922\n",
      "Epoch 520/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0484 - val_binary_accuracy: 0.9922\n",
      "Epoch 521/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 522/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0491 - val_binary_accuracy: 0.9922\n",
      "Epoch 523/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 524/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0483 - val_binary_accuracy: 0.9922\n",
      "Epoch 525/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0633 - binary_accuracy: 0.9796 - val_loss: 0.0492 - val_binary_accuracy: 0.9922\n",
      "Epoch 526/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0458 - val_binary_accuracy: 0.9922\n",
      "Epoch 527/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 528/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 529/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0492 - val_binary_accuracy: 0.9922\n",
      "Epoch 530/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 531/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 532/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0465 - val_binary_accuracy: 0.9922\n",
      "Epoch 533/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0463 - val_binary_accuracy: 0.9922\n",
      "Epoch 534/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 535/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0474 - val_binary_accuracy: 0.9922\n",
      "Epoch 536/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 537/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0479 - val_binary_accuracy: 0.9922\n",
      "Epoch 538/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0473 - val_binary_accuracy: 0.9922\n",
      "Epoch 539/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 540/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 541/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 542/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 543/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 544/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 545/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 546/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 547/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 548/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0493 - val_binary_accuracy: 0.9922\n",
      "Epoch 549/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 550/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0458 - val_binary_accuracy: 0.9922\n",
      "Epoch 551/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0633 - binary_accuracy: 0.9796 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 552/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 553/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 554/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 555/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0448 - val_binary_accuracy: 0.9923\n",
      "Epoch 556/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0487 - val_binary_accuracy: 0.9922\n",
      "Epoch 557/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0487 - val_binary_accuracy: 0.9922\n",
      "Epoch 558/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 559/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0479 - val_binary_accuracy: 0.9922\n",
      "Epoch 560/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0479 - val_binary_accuracy: 0.9922\n",
      "Epoch 561/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0474 - val_binary_accuracy: 0.9922\n",
      "Epoch 562/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 563/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0495 - val_binary_accuracy: 0.9922\n",
      "Epoch 564/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0490 - val_binary_accuracy: 0.9922\n",
      "Epoch 565/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 566/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 567/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0633 - binary_accuracy: 0.9796 - val_loss: 0.0461 - val_binary_accuracy: 0.9923\n",
      "Epoch 568/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0462 - val_binary_accuracy: 0.9922\n",
      "Epoch 569/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0480 - val_binary_accuracy: 0.9923\n",
      "Epoch 570/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0479 - val_binary_accuracy: 0.9922\n",
      "Epoch 571/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0470 - val_binary_accuracy: 0.9923\n",
      "Epoch 572/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 573/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 574/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 575/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0474 - val_binary_accuracy: 0.9922\n",
      "Epoch 576/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0475 - val_binary_accuracy: 0.9922\n",
      "Epoch 577/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0475 - val_binary_accuracy: 0.9922\n",
      "Epoch 578/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 579/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 580/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0484 - val_binary_accuracy: 0.9922\n",
      "Epoch 581/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 582/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0463 - val_binary_accuracy: 0.9922\n",
      "Epoch 583/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0455 - val_binary_accuracy: 0.9922\n",
      "Epoch 584/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0450 - val_binary_accuracy: 0.9923\n",
      "Epoch 585/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 586/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 587/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0475 - val_binary_accuracy: 0.9922\n",
      "Epoch 588/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 589/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 590/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 591/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0458 - val_binary_accuracy: 0.9922\n",
      "Epoch 592/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0454 - val_binary_accuracy: 0.9923\n",
      "Epoch 593/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0463 - val_binary_accuracy: 0.9922\n",
      "Epoch 594/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0422 - val_binary_accuracy: 0.9922\n",
      "Epoch 595/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0445 - val_binary_accuracy: 0.9922\n",
      "Epoch 596/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0443 - val_binary_accuracy: 0.9922\n",
      "Epoch 597/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0468 - val_binary_accuracy: 0.9922\n",
      "Epoch 598/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0450 - val_binary_accuracy: 0.9922\n",
      "Epoch 599/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 600/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 601/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0489 - val_binary_accuracy: 0.9922\n",
      "Epoch 602/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0483 - val_binary_accuracy: 0.9922\n",
      "Epoch 603/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0489 - val_binary_accuracy: 0.9922\n",
      "Epoch 604/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0482 - val_binary_accuracy: 0.9922\n",
      "Epoch 605/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0486 - val_binary_accuracy: 0.9922\n",
      "Epoch 606/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0453 - val_binary_accuracy: 0.9922\n",
      "Epoch 607/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0485 - val_binary_accuracy: 0.9923\n",
      "Epoch 608/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0459 - val_binary_accuracy: 0.9922\n",
      "Epoch 609/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0468 - val_binary_accuracy: 0.9922\n",
      "Epoch 610/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0484 - val_binary_accuracy: 0.9922\n",
      "Epoch 611/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0496 - val_binary_accuracy: 0.9922\n",
      "Epoch 612/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 613/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 614/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0479 - val_binary_accuracy: 0.9922\n",
      "Epoch 615/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 616/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0491 - val_binary_accuracy: 0.9922\n",
      "Epoch 617/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0465 - val_binary_accuracy: 0.9922\n",
      "Epoch 618/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 619/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 620/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0480 - val_binary_accuracy: 0.9923\n",
      "Epoch 621/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 622/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 623/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0642 - binary_accuracy: 0.9796 - val_loss: 0.0458 - val_binary_accuracy: 0.9922\n",
      "Epoch 624/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0470 - val_binary_accuracy: 0.9922\n",
      "Epoch 625/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0479 - val_binary_accuracy: 0.9922\n",
      "Epoch 626/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0492 - val_binary_accuracy: 0.9922\n",
      "Epoch 627/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0465 - val_binary_accuracy: 0.9922\n",
      "Epoch 628/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 629/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0482 - val_binary_accuracy: 0.9922\n",
      "Epoch 630/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0483 - val_binary_accuracy: 0.9922\n",
      "Epoch 631/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 632/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0491 - val_binary_accuracy: 0.9922\n",
      "Epoch 633/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0449 - val_binary_accuracy: 0.9922\n",
      "Epoch 634/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 635/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 636/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0489 - val_binary_accuracy: 0.9922\n",
      "Epoch 637/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 638/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0489 - val_binary_accuracy: 0.9923\n",
      "Epoch 639/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0501 - val_binary_accuracy: 0.9922\n",
      "Epoch 640/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0450 - val_binary_accuracy: 0.9922\n",
      "Epoch 641/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 642/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 643/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0473 - val_binary_accuracy: 0.9922\n",
      "Epoch 644/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0485 - val_binary_accuracy: 0.9922\n",
      "Epoch 645/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0493 - val_binary_accuracy: 0.9922\n",
      "Epoch 646/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0466 - val_binary_accuracy: 0.9922\n",
      "Epoch 647/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0470 - val_binary_accuracy: 0.9922\n",
      "Epoch 648/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 649/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0496 - val_binary_accuracy: 0.9922\n",
      "Epoch 650/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0469 - val_binary_accuracy: 0.9923\n",
      "Epoch 651/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 652/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0482 - val_binary_accuracy: 0.9922\n",
      "Epoch 653/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0493 - val_binary_accuracy: 0.9922\n",
      "Epoch 654/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0498 - val_binary_accuracy: 0.9922\n",
      "Epoch 655/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0511 - val_binary_accuracy: 0.9922\n",
      "Epoch 656/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0462 - val_binary_accuracy: 0.9922\n",
      "Epoch 657/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0494 - val_binary_accuracy: 0.9922\n",
      "Epoch 658/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0477 - val_binary_accuracy: 0.9923\n",
      "Epoch 659/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0505 - val_binary_accuracy: 0.9922\n",
      "Epoch 660/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0505 - val_binary_accuracy: 0.9922\n",
      "Epoch 661/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 662/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0493 - val_binary_accuracy: 0.9922\n",
      "Epoch 663/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 664/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 665/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0486 - val_binary_accuracy: 0.9922\n",
      "Epoch 666/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0487 - val_binary_accuracy: 0.9922\n",
      "Epoch 667/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 668/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 669/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 670/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 671/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0497 - val_binary_accuracy: 0.9922\n",
      "Epoch 672/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0500 - val_binary_accuracy: 0.9922\n",
      "Epoch 673/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0511 - val_binary_accuracy: 0.9922\n",
      "Epoch 674/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0521 - val_binary_accuracy: 0.9922\n",
      "Epoch 675/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 676/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 677/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 678/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0474 - val_binary_accuracy: 0.9922\n",
      "Epoch 679/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0490 - val_binary_accuracy: 0.9922\n",
      "Epoch 680/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0489 - val_binary_accuracy: 0.9922\n",
      "Epoch 681/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 682/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0633 - binary_accuracy: 0.9795 - val_loss: 0.0489 - val_binary_accuracy: 0.9922\n",
      "Epoch 683/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0494 - val_binary_accuracy: 0.9922\n",
      "Epoch 684/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0490 - val_binary_accuracy: 0.9922\n",
      "Epoch 685/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0456 - val_binary_accuracy: 0.9922\n",
      "Epoch 686/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 687/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0479 - val_binary_accuracy: 0.9922\n",
      "Epoch 688/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 689/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 690/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0486 - val_binary_accuracy: 0.9922\n",
      "Epoch 691/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0473 - val_binary_accuracy: 0.9922\n",
      "Epoch 692/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0639 - binary_accuracy: 0.9795 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 693/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0495 - val_binary_accuracy: 0.9922\n",
      "Epoch 694/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0508 - val_binary_accuracy: 0.9922\n",
      "Epoch 695/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 696/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0496 - val_binary_accuracy: 0.9922\n",
      "Epoch 697/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 698/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0463 - val_binary_accuracy: 0.9922\n",
      "Epoch 699/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 700/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0474 - val_binary_accuracy: 0.9922\n",
      "Epoch 701/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0490 - val_binary_accuracy: 0.9922\n",
      "Epoch 702/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 703/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0510 - val_binary_accuracy: 0.9922\n",
      "Epoch 704/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 705/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 706/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0476 - val_binary_accuracy: 0.9922\n",
      "Epoch 707/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0498 - val_binary_accuracy: 0.9922\n",
      "Epoch 708/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0502 - val_binary_accuracy: 0.9922\n",
      "Epoch 709/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0514 - val_binary_accuracy: 0.9922\n",
      "Epoch 710/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0508 - val_binary_accuracy: 0.9922\n",
      "Epoch 711/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0514 - val_binary_accuracy: 0.9922\n",
      "Epoch 712/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0520 - val_binary_accuracy: 0.9922\n",
      "Epoch 713/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0525 - val_binary_accuracy: 0.9922\n",
      "Epoch 714/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0498 - val_binary_accuracy: 0.9922\n",
      "Epoch 715/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0496 - val_binary_accuracy: 0.9922\n",
      "Epoch 716/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 717/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0462 - val_binary_accuracy: 0.9922\n",
      "Epoch 718/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0640 - binary_accuracy: 0.9795 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 719/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0496 - val_binary_accuracy: 0.9922\n",
      "Epoch 720/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0492 - val_binary_accuracy: 0.9922\n",
      "Epoch 721/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0495 - val_binary_accuracy: 0.9922\n",
      "Epoch 722/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0462 - val_binary_accuracy: 0.9922\n",
      "Epoch 723/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0481 - val_binary_accuracy: 0.9922\n",
      "Epoch 724/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0475 - val_binary_accuracy: 0.9922\n",
      "Epoch 725/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0457 - val_binary_accuracy: 0.9921\n",
      "Epoch 726/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0468 - val_binary_accuracy: 0.9921\n",
      "Epoch 727/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0477 - val_binary_accuracy: 0.9922\n",
      "Epoch 728/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0478 - val_binary_accuracy: 0.9922\n",
      "Epoch 729/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0495 - val_binary_accuracy: 0.9922\n",
      "Epoch 730/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0490 - val_binary_accuracy: 0.9921\n",
      "Epoch 731/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0480 - val_binary_accuracy: 0.9921\n",
      "Epoch 732/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0458 - val_binary_accuracy: 0.9922\n",
      "Epoch 733/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0482 - val_binary_accuracy: 0.9922\n",
      "Epoch 734/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0482 - val_binary_accuracy: 0.9922\n",
      "Epoch 735/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0484 - val_binary_accuracy: 0.9922\n",
      "Epoch 736/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0512 - val_binary_accuracy: 0.9922\n",
      "Epoch 737/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 738/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0494 - val_binary_accuracy: 0.9922\n",
      "Epoch 739/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0501 - val_binary_accuracy: 0.9922\n",
      "Epoch 740/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0499 - val_binary_accuracy: 0.9923\n",
      "Epoch 741/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0494 - val_binary_accuracy: 0.9923\n",
      "Epoch 742/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 743/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0473 - val_binary_accuracy: 0.9923\n",
      "Epoch 744/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0501 - val_binary_accuracy: 0.9922\n",
      "Epoch 745/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 746/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0490 - val_binary_accuracy: 0.9922\n",
      "Epoch 747/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0495 - val_binary_accuracy: 0.9922\n",
      "Epoch 748/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0482 - val_binary_accuracy: 0.9923\n",
      "Epoch 749/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0506 - val_binary_accuracy: 0.9921\n",
      "Epoch 750/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 751/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0495 - val_binary_accuracy: 0.9922\n",
      "Epoch 752/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0479 - val_binary_accuracy: 0.9921\n",
      "Epoch 753/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0489 - val_binary_accuracy: 0.9922\n",
      "Epoch 754/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0494 - val_binary_accuracy: 0.9922\n",
      "Epoch 755/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0503 - val_binary_accuracy: 0.9922\n",
      "Epoch 756/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 757/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0487 - val_binary_accuracy: 0.9922\n",
      "Epoch 758/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0502 - val_binary_accuracy: 0.9922\n",
      "Epoch 759/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0509 - val_binary_accuracy: 0.9921\n",
      "Epoch 760/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0485 - val_binary_accuracy: 0.9921\n",
      "Epoch 761/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0459 - val_binary_accuracy: 0.9921\n",
      "Epoch 762/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0475 - val_binary_accuracy: 0.9922\n",
      "Epoch 763/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0483 - val_binary_accuracy: 0.9921\n",
      "Epoch 764/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0493 - val_binary_accuracy: 0.9922\n",
      "Epoch 765/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0494 - val_binary_accuracy: 0.9922\n",
      "Epoch 766/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0497 - val_binary_accuracy: 0.9922\n",
      "Epoch 767/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0451 - val_binary_accuracy: 0.9922\n",
      "Epoch 768/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0464 - val_binary_accuracy: 0.9922\n",
      "Epoch 769/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 770/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0498 - val_binary_accuracy: 0.9922\n",
      "Epoch 771/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0510 - val_binary_accuracy: 0.9922\n",
      "Epoch 772/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0470 - val_binary_accuracy: 0.9922\n",
      "Epoch 773/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0468 - val_binary_accuracy: 0.9922\n",
      "Epoch 774/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0485 - val_binary_accuracy: 0.9922\n",
      "Epoch 775/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0486 - val_binary_accuracy: 0.9922\n",
      "Epoch 776/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0499 - val_binary_accuracy: 0.9923\n",
      "Epoch 777/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0508 - val_binary_accuracy: 0.9922\n",
      "Epoch 778/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0509 - val_binary_accuracy: 0.9922\n",
      "Epoch 779/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 780/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 781/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0467 - val_binary_accuracy: 0.9922\n",
      "Epoch 782/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0485 - val_binary_accuracy: 0.9922\n",
      "Epoch 783/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 784/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 785/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0500 - val_binary_accuracy: 0.9922\n",
      "Epoch 786/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9796 - val_loss: 0.0502 - val_binary_accuracy: 0.9923\n",
      "Epoch 787/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0512 - val_binary_accuracy: 0.9923\n",
      "Epoch 788/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0497 - val_binary_accuracy: 0.9922\n",
      "Epoch 789/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0492 - val_binary_accuracy: 0.9922\n",
      "Epoch 790/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 791/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0511 - val_binary_accuracy: 0.9922\n",
      "Epoch 792/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0484 - val_binary_accuracy: 0.9922\n",
      "Epoch 793/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0490 - val_binary_accuracy: 0.9923\n",
      "Epoch 794/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0488 - val_binary_accuracy: 0.9922\n",
      "Epoch 795/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0502 - val_binary_accuracy: 0.9922\n",
      "Epoch 796/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0514 - val_binary_accuracy: 0.9922\n",
      "Epoch 797/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0537 - val_binary_accuracy: 0.9923\n",
      "Epoch 798/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0528 - val_binary_accuracy: 0.9923\n",
      "Epoch 799/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0535 - val_binary_accuracy: 0.9923\n",
      "Epoch 800/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0522 - val_binary_accuracy: 0.9922\n",
      "Epoch 801/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0516 - val_binary_accuracy: 0.9922\n",
      "Epoch 802/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0473 - val_binary_accuracy: 0.9922\n",
      "Epoch 803/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0483 - val_binary_accuracy: 0.9922\n",
      "Epoch 804/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0489 - val_binary_accuracy: 0.9922\n",
      "Epoch 805/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0496 - val_binary_accuracy: 0.9922\n",
      "Epoch 806/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0493 - val_binary_accuracy: 0.9923\n",
      "Epoch 807/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0460 - val_binary_accuracy: 0.9922\n",
      "Epoch 808/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0473 - val_binary_accuracy: 0.9922\n",
      "Epoch 809/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0484 - val_binary_accuracy: 0.9922\n",
      "Epoch 810/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0491 - val_binary_accuracy: 0.9922\n",
      "Epoch 811/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0508 - val_binary_accuracy: 0.9922\n",
      "Epoch 812/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0521 - val_binary_accuracy: 0.9921\n",
      "Epoch 813/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0517 - val_binary_accuracy: 0.9921\n",
      "Epoch 814/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 815/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0470 - val_binary_accuracy: 0.9923\n",
      "Epoch 816/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0480 - val_binary_accuracy: 0.9922\n",
      "Epoch 817/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0502 - val_binary_accuracy: 0.9924\n",
      "Epoch 818/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0517 - val_binary_accuracy: 0.9923\n",
      "Epoch 819/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0508 - val_binary_accuracy: 0.9922\n",
      "Epoch 820/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0500 - val_binary_accuracy: 0.9922\n",
      "Epoch 821/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0519 - val_binary_accuracy: 0.9922\n",
      "Epoch 822/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0536 - val_binary_accuracy: 0.9922\n",
      "Epoch 823/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0524 - val_binary_accuracy: 0.9922\n",
      "Epoch 824/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0524 - val_binary_accuracy: 0.9922\n",
      "Epoch 825/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0523 - val_binary_accuracy: 0.9922\n",
      "Epoch 826/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0504 - val_binary_accuracy: 0.9922\n",
      "Epoch 827/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 828/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0533 - val_binary_accuracy: 0.9922\n",
      "Epoch 829/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0521 - val_binary_accuracy: 0.9922\n",
      "Epoch 830/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0525 - val_binary_accuracy: 0.9922\n",
      "Epoch 831/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0521 - val_binary_accuracy: 0.9922\n",
      "Epoch 832/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0491 - val_binary_accuracy: 0.9922\n",
      "Epoch 833/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0519 - val_binary_accuracy: 0.9922\n",
      "Epoch 834/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0524 - val_binary_accuracy: 0.9922\n",
      "Epoch 835/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0531 - val_binary_accuracy: 0.9922\n",
      "Epoch 836/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0500 - val_binary_accuracy: 0.9922\n",
      "Epoch 837/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0516 - val_binary_accuracy: 0.9922\n",
      "Epoch 838/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0516 - val_binary_accuracy: 0.9922\n",
      "Epoch 839/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0521 - val_binary_accuracy: 0.9922\n",
      "Epoch 840/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0531 - val_binary_accuracy: 0.9922\n",
      "Epoch 841/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0493 - val_binary_accuracy: 0.9922\n",
      "Epoch 842/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0503 - val_binary_accuracy: 0.9922\n",
      "Epoch 843/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0492 - val_binary_accuracy: 0.9922\n",
      "Epoch 844/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0519 - val_binary_accuracy: 0.9922\n",
      "Epoch 845/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0514 - val_binary_accuracy: 0.9922\n",
      "Epoch 846/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0540 - val_binary_accuracy: 0.9922\n",
      "Epoch 847/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0537 - val_binary_accuracy: 0.9922\n",
      "Epoch 848/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0525 - val_binary_accuracy: 0.9922\n",
      "Epoch 849/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0501 - val_binary_accuracy: 0.9922\n",
      "Epoch 850/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0514 - val_binary_accuracy: 0.9922\n",
      "Epoch 851/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0523 - val_binary_accuracy: 0.9922\n",
      "Epoch 852/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0498 - val_binary_accuracy: 0.9922\n",
      "Epoch 853/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0484 - val_binary_accuracy: 0.9923\n",
      "Epoch 854/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0469 - val_binary_accuracy: 0.9922\n",
      "Epoch 855/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0471 - val_binary_accuracy: 0.9922\n",
      "Epoch 856/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0499 - val_binary_accuracy: 0.9922\n",
      "Epoch 857/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0472 - val_binary_accuracy: 0.9922\n",
      "Epoch 858/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0505 - val_binary_accuracy: 0.9922\n",
      "Epoch 859/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0508 - val_binary_accuracy: 0.9922\n",
      "Epoch 860/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 861/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0527 - val_binary_accuracy: 0.9922\n",
      "Epoch 862/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0518 - val_binary_accuracy: 0.9922\n",
      "Epoch 863/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0505 - val_binary_accuracy: 0.9922\n",
      "Epoch 864/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 865/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0523 - val_binary_accuracy: 0.9922\n",
      "Epoch 866/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0526 - val_binary_accuracy: 0.9922\n",
      "Epoch 867/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0534 - val_binary_accuracy: 0.9922\n",
      "Epoch 868/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0519 - val_binary_accuracy: 0.9922\n",
      "Epoch 869/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0512 - val_binary_accuracy: 0.9922\n",
      "Epoch 870/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0507 - val_binary_accuracy: 0.9922\n",
      "Epoch 871/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0505 - val_binary_accuracy: 0.9922\n",
      "Epoch 872/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0520 - val_binary_accuracy: 0.9922\n",
      "Epoch 873/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0515 - val_binary_accuracy: 0.9923\n",
      "Epoch 874/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0529 - val_binary_accuracy: 0.9923\n",
      "Epoch 875/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0492 - val_binary_accuracy: 0.9923\n",
      "Epoch 876/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 877/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0517 - val_binary_accuracy: 0.9923\n",
      "Epoch 878/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0509 - val_binary_accuracy: 0.9923\n",
      "Epoch 879/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0546 - val_binary_accuracy: 0.9923\n",
      "Epoch 880/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0540 - val_binary_accuracy: 0.9922\n",
      "Epoch 881/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0528 - val_binary_accuracy: 0.9922\n",
      "Epoch 882/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0511 - val_binary_accuracy: 0.9923\n",
      "Epoch 883/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0539 - val_binary_accuracy: 0.9922\n",
      "Epoch 884/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0510 - val_binary_accuracy: 0.9922\n",
      "Epoch 885/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0524 - val_binary_accuracy: 0.9923\n",
      "Epoch 886/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0532 - val_binary_accuracy: 0.9922\n",
      "Epoch 887/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0554 - val_binary_accuracy: 0.9922\n",
      "Epoch 888/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0515 - val_binary_accuracy: 0.9922\n",
      "Epoch 889/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0540 - val_binary_accuracy: 0.9922\n",
      "Epoch 890/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0524 - val_binary_accuracy: 0.9922\n",
      "Epoch 891/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0545 - val_binary_accuracy: 0.9922\n",
      "Epoch 892/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0529 - val_binary_accuracy: 0.9923\n",
      "Epoch 893/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0638 - binary_accuracy: 0.9795 - val_loss: 0.0572 - val_binary_accuracy: 0.9922\n",
      "Epoch 894/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0515 - val_binary_accuracy: 0.9922\n",
      "Epoch 895/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0509 - val_binary_accuracy: 0.9922\n",
      "Epoch 896/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0523 - val_binary_accuracy: 0.9922\n",
      "Epoch 897/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0526 - val_binary_accuracy: 0.9922\n",
      "Epoch 898/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0536 - val_binary_accuracy: 0.9922\n",
      "Epoch 899/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0546 - val_binary_accuracy: 0.9922\n",
      "Epoch 900/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0542 - val_binary_accuracy: 0.9922\n",
      "Epoch 901/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0557 - val_binary_accuracy: 0.9922\n",
      "Epoch 902/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0510 - val_binary_accuracy: 0.9922\n",
      "Epoch 903/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0510 - val_binary_accuracy: 0.9922\n",
      "Epoch 904/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0522 - val_binary_accuracy: 0.9923\n",
      "Epoch 905/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0524 - val_binary_accuracy: 0.9923\n",
      "Epoch 906/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0538 - val_binary_accuracy: 0.9922\n",
      "Epoch 907/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0560 - val_binary_accuracy: 0.9922\n",
      "Epoch 908/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0545 - val_binary_accuracy: 0.9922\n",
      "Epoch 909/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0547 - val_binary_accuracy: 0.9922\n",
      "Epoch 910/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0559 - val_binary_accuracy: 0.9922\n",
      "Epoch 911/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0517 - val_binary_accuracy: 0.9922\n",
      "Epoch 912/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0514 - val_binary_accuracy: 0.9922\n",
      "Epoch 913/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0529 - val_binary_accuracy: 0.9922\n",
      "Epoch 914/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0543 - val_binary_accuracy: 0.9922\n",
      "Epoch 915/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0533 - val_binary_accuracy: 0.9922\n",
      "Epoch 916/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0543 - val_binary_accuracy: 0.9923\n",
      "Epoch 917/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0558 - val_binary_accuracy: 0.9922\n",
      "Epoch 918/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0579 - val_binary_accuracy: 0.9922\n",
      "Epoch 919/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0525 - val_binary_accuracy: 0.9922\n",
      "Epoch 920/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0539 - val_binary_accuracy: 0.9923\n",
      "Epoch 921/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0545 - val_binary_accuracy: 0.9922\n",
      "Epoch 922/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0571 - val_binary_accuracy: 0.9922\n",
      "Epoch 923/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0531 - val_binary_accuracy: 0.9922\n",
      "Epoch 924/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0553 - val_binary_accuracy: 0.9922\n",
      "Epoch 925/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0551 - val_binary_accuracy: 0.9922\n",
      "Epoch 926/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0525 - val_binary_accuracy: 0.9922\n",
      "Epoch 927/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0547 - val_binary_accuracy: 0.9922\n",
      "Epoch 928/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0562 - val_binary_accuracy: 0.9922\n",
      "Epoch 929/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0576 - val_binary_accuracy: 0.9922\n",
      "Epoch 930/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0583 - val_binary_accuracy: 0.9922\n",
      "Epoch 931/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0569 - val_binary_accuracy: 0.9922\n",
      "Epoch 932/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0585 - val_binary_accuracy: 0.9922\n",
      "Epoch 933/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0579 - val_binary_accuracy: 0.9922\n",
      "Epoch 934/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0578 - val_binary_accuracy: 0.9922\n",
      "Epoch 935/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0583 - val_binary_accuracy: 0.9922\n",
      "Epoch 936/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0553 - val_binary_accuracy: 0.9922\n",
      "Epoch 937/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0545 - val_binary_accuracy: 0.9922\n",
      "Epoch 938/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0555 - val_binary_accuracy: 0.9922\n",
      "Epoch 939/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0537 - val_binary_accuracy: 0.9922\n",
      "Epoch 940/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0575 - val_binary_accuracy: 0.9922\n",
      "Epoch 941/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0538 - val_binary_accuracy: 0.9922\n",
      "Epoch 942/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0557 - val_binary_accuracy: 0.9922\n",
      "Epoch 943/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0576 - val_binary_accuracy: 0.9922\n",
      "Epoch 944/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0506 - val_binary_accuracy: 0.9922\n",
      "Epoch 945/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0544 - val_binary_accuracy: 0.9922\n",
      "Epoch 946/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0562 - val_binary_accuracy: 0.9922\n",
      "Epoch 947/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0565 - val_binary_accuracy: 0.9923\n",
      "Epoch 948/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9796 - val_loss: 0.0580 - val_binary_accuracy: 0.9922\n",
      "Epoch 949/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0588 - val_binary_accuracy: 0.9922\n",
      "Epoch 950/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0612 - val_binary_accuracy: 0.9922\n",
      "Epoch 951/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0548 - val_binary_accuracy: 0.9923\n",
      "Epoch 952/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0596 - val_binary_accuracy: 0.9922\n",
      "Epoch 953/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0569 - val_binary_accuracy: 0.9922\n",
      "Epoch 954/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0594 - val_binary_accuracy: 0.9922\n",
      "Epoch 955/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0587 - val_binary_accuracy: 0.9922\n",
      "Epoch 956/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0566 - val_binary_accuracy: 0.9922\n",
      "Epoch 957/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0572 - val_binary_accuracy: 0.9922\n",
      "Epoch 958/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0592 - val_binary_accuracy: 0.9922\n",
      "Epoch 959/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0593 - val_binary_accuracy: 0.9922\n",
      "Epoch 960/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0593 - val_binary_accuracy: 0.9922\n",
      "Epoch 961/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0580 - val_binary_accuracy: 0.9922\n",
      "Epoch 962/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0596 - val_binary_accuracy: 0.9922\n",
      "Epoch 963/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0607 - val_binary_accuracy: 0.9922\n",
      "Epoch 964/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0572 - val_binary_accuracy: 0.9922\n",
      "Epoch 965/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0569 - val_binary_accuracy: 0.9922\n",
      "Epoch 966/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0568 - val_binary_accuracy: 0.9922\n",
      "Epoch 967/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0562 - val_binary_accuracy: 0.9922\n",
      "Epoch 968/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0583 - val_binary_accuracy: 0.9922\n",
      "Epoch 969/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0580 - val_binary_accuracy: 0.9922\n",
      "Epoch 970/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0606 - val_binary_accuracy: 0.9922\n",
      "Epoch 971/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0612 - val_binary_accuracy: 0.9922\n",
      "Epoch 972/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0622 - val_binary_accuracy: 0.9922\n",
      "Epoch 973/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0653 - val_binary_accuracy: 0.9922\n",
      "Epoch 974/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0606 - val_binary_accuracy: 0.9922\n",
      "Epoch 975/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0562 - val_binary_accuracy: 0.9922\n",
      "Epoch 976/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0618 - val_binary_accuracy: 0.9922\n",
      "Epoch 977/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0612 - val_binary_accuracy: 0.9922\n",
      "Epoch 978/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0637 - binary_accuracy: 0.9795 - val_loss: 0.0616 - val_binary_accuracy: 0.9922\n",
      "Epoch 979/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0627 - val_binary_accuracy: 0.9922\n",
      "Epoch 980/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0662 - val_binary_accuracy: 0.9922\n",
      "Epoch 981/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0628 - val_binary_accuracy: 0.9922\n",
      "Epoch 982/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0615 - val_binary_accuracy: 0.9922\n",
      "Epoch 983/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0584 - val_binary_accuracy: 0.9923\n",
      "Epoch 984/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0616 - val_binary_accuracy: 0.9922\n",
      "Epoch 985/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0635 - val_binary_accuracy: 0.9922\n",
      "Epoch 986/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0613 - val_binary_accuracy: 0.9922\n",
      "Epoch 987/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0629 - val_binary_accuracy: 0.9923\n",
      "Epoch 988/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9795 - val_loss: 0.0636 - val_binary_accuracy: 0.9922\n",
      "Epoch 989/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0600 - val_binary_accuracy: 0.9922\n",
      "Epoch 990/1000\n",
      "386/386 [==============================] - 2s 6ms/step - loss: 0.0634 - binary_accuracy: 0.9795 - val_loss: 0.0584 - val_binary_accuracy: 0.9922\n",
      "Epoch 991/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0597 - val_binary_accuracy: 0.9922\n",
      "Epoch 992/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9795 - val_loss: 0.0627 - val_binary_accuracy: 0.9922\n",
      "Epoch 993/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0627 - val_binary_accuracy: 0.9922\n",
      "Epoch 994/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0655 - val_binary_accuracy: 0.9922\n",
      "Epoch 995/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0635 - binary_accuracy: 0.9796 - val_loss: 0.0623 - val_binary_accuracy: 0.9922\n",
      "Epoch 996/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0647 - val_binary_accuracy: 0.9922\n",
      "Epoch 997/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0631 - val_binary_accuracy: 0.9922\n",
      "Epoch 998/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0666 - val_binary_accuracy: 0.9922\n",
      "Epoch 999/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0634 - binary_accuracy: 0.9796 - val_loss: 0.0668 - val_binary_accuracy: 0.9922\n",
      "Epoch 1000/1000\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0636 - binary_accuracy: 0.9796 - val_loss: 0.0600 - val_binary_accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# early stopping to prevent overfitting\n",
    "callback = callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=30, min_delta=0.001, restore_best_weights=True)\n",
    "# model training\n",
    "model_nn = ModelCreate((len(features_nn),))\n",
    "history = model_nn.fit(train_X1[features_nn], train_Y, batch_size=1024, validation_split=0.2, epochs=1000, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyK0lEQVR4nO3deZgdVb3v//e3d89TujsTnXSSjhAgCZAEmuAACEZkOEhk8EA8XkEGRQ/gcI8eHM5P7vV6fhyFox71kR8ICkc0F9Ag8oCIIAKiQIAQMpI56Yyd7vQ8d39/f6zq7p2esnfIJkn35/U8++ldq2pVrVV7d31rrbWrytwdERGRRKUd7gKIiMjRRYFDRESSosAhIiJJUeAQEZGkKHCIiEhSFDhERCQpChwiQzCzcjNzM0tPYNlrzOzFd6NcIoebAoeMCGa22czazWxcv/Rl0cG//DAVTWTEUeCQkWQTsKhnwsxOBnIOX3GODIm0mESSocAhI8l/A5+Km74aeCB+ATMbY2YPmFmVmW0xs2+aWVo0L2Zmd5jZXjPbCPzDIHnvNbOdZrbdzP6PmcUSKZiZPWxmu8yszsyeN7PZcfNyzOzOqDx1ZvaimeVE8840s5fMrNbMtpnZNVH6c2Z2fdw69usqi1pZ/2xm64B1UdoPo3XUm9lrZnZW3PIxM/u6mW0ws4Zo/hQz+4mZ3dmvLr83sy8mUm8ZmRQ4ZCT5O1BoZjOjA/qVwC/7LfMjYAzwHuCDhEDz6WjeDcDFwDygAriiX977gU7guGiZjwDXk5gngRnABOB14MG4eXcApwHvB0qArwLdZjY1yvcjYDwwF1iW4PYAPgacAcyKpl+N1lEC/Ap42Myyo3lfJrTWLgIKgWuBZkKdF8UF13HAAuDXSZRDRhp310uvo/4FbAY+DHwT+H+BC4CngXTAgXIgBrQBs+LyfRZ4Lnr/LHBj3LyPRHnTgYlR3py4+YuAP0fvrwFeTLCsRdF6xxBO3lqAOYMs9zVgyRDreA64Pm56v+1H6//QAcqxr2e7wFpg4RDLrQbOi97fBDxxuD9vvQ7vS32fMtL8N/A8MJ1+3VTAOCAT2BKXtgWYHL2fBGzrN6/HNCAD2GlmPWlp/ZYfVNT6+Q7wcULLoTuuPFlANrBhkKxThkhP1H5lM7P/SWghTSIElsKoDAfa1v3AJwmB+JPAD99BmWQEUFeVjCjuvoUwSH4R8Nt+s/cCHYQg0GMqsD16v5NwAI2f12MbocUxzt2Lolehu8/mwD4BLCS0iMYQWj8AFpWpFTh2kHzbhkgHaAJy46aPGWSZ3ltfR+MZ/wr8I1Ds7kVAXVSGA23rl8BCM5sDzAQeHWI5GSUUOGQkuo7QTdMUn+juXcBDwHfMrMDMphH69nvGQR4CbjGzMjMrBm6Ny7sT+CNwp5kVmlmamR1rZh9MoDwFhKBTTTjY/3vceruB+4D/NLNJ0SD1+8wsizAO8mEz+0czSzezsWY2N8q6DLjMzHLN7LiozgcqQydQBaSb2f9DaHH0+BnwbTObYcEpZjY2KmMlYXzkv4HfuHtLAnWWEUyBQ0Ycd9/g7kuHmH0z4Wx9I/AiYZD4vmjePcBTwJuEAez+LZZPEbq6VhHGBx4BShMo0gOEbq/tUd6/95v/L8BbhINzDfAfQJq7byW0nP5nlL4MmBPl+T7QDuwmdCU9yPCeIgy0vx2VpZX9u7L+kxA4/wjUA/ey/0+Z7wdOJgQPGeXMXQ9yEpHhmdnZhJZZedRKklFMLQ4RGZaZZQBfAH6moCGgwCEiwzCzmUAtoUvuB4e1MHLEUFeViIgkRS0OERFJyqi4AHDcuHFeXl5+uIshInJUee211/a6+/j+6aMicJSXl7N06VC/zhQRkcGY2ZbB0tVVJSIiSVHgEBGRpChwiIhIUkbFGMdgOjo6qKyspLW19XAX5YiXnZ1NWVkZGRkZh7soInIEGLWBo7KykoKCAsrLy4m7Tbb04+5UV1dTWVnJ9OnTD3dxROQIMGq7qlpbWxk7dqyCxgGYGWPHjlXLTER6jdrAAShoJEj7SUTijerAcUDtzVC/A9oaDndJRESOGAocw2muhsbdUL0e2hqhuxNa66CxCrq7wnRnG9RuC6/mmhBkel7dXdDVEd53toX1tTVCaz3VuyqZO3cuc+fO5ZhjjmHy5Mm90+1tbRB/E9LubuhsD+vqaGXp3//KLbfcEs3rBPeoPF1xebqi9O6wza6O/Zfvme5Ji8/r3SGtvTmUO35ee9yzkVrrwvr7pwO01EJHC2x7BfZF1xC5hzwQ6tPZHraRqNb6UJaO1r4ytTWEbcRr3AO73uqbbmuErs6onINsr6W2r1w99RpOzzq6os+/R0drqHN8WRPV3hTK0VO/RHW07F+G9iZoqg77Or687uHVv/47loXvbXz+/vev65+vvSl8du6hzKnU0QqbXgj7s61x+H3avzwNu8L3c9MLoY5N1SG9Z5muTnjjQajZmFhZBts3EP73t74MNZtg84t9J5ottfsv31gVt67msL62xgNvs/96BtPRGradzP/TOzAqbnJYUVHh/a8cX716NTNnzhw+Y8s+2Lc5dQWLntp5250/Jb+whH+54R+j5DQ6O9pJzx8Hna3h1V/u2BCIADJywhfHDNLSoaAUareAxaIA1PMZp9H3uGsgawx0NIUgAZCZD2kZ0FYPvv8/6OrKWma+dTtsi55BVDQVarfChNlQcAxseAamnRneb34RGnftX94TLw4H+KY9kFMS0lpqQhlPuBC2vQxNVZA3HibNg6zo4XS7loc6NewMn0d2UShvVgFMOQNWPRqWO+7DYR7AikfC32M/FNbTs0y8CbNhwkxY9zS01fWVcf0z0NkC0z4Ae9eFMp1wIWRET2ltrYP1T8PZX4G3HoF9m2DG+ZBTDCuXQFcbzLwEVj8Wls8bH15dHZCVDxl54Ts19b1hfmdrOODsWdlXtsx8OP582LMGCktDvcygcBJUrQ2faXYRtNbCuj+GPOVnhdZxTfTY8MKykLd6Q9jPBaWQmRdOgqZ/MHxn0tJhzeNh+ZOugM0vhKA77ng45uRwALQ0ePvJsMx7/zmcSPXs3x7zPxPq99rPw3cqtwQmnwZzFoX1N1X1fcd2rwz7vbkmBLzCUlj/p/B9LpwEp10DJ10e5j3/Pdj7Nmx8rm9bZ9wYPqc3fgmnXxcO+isfhbHHwt9+HJaZfnY4SFetHvi5Wyx8t2ctDJ/vnlVR/S8HLHzf8ieGV+NuaG+EkmNh0/OhHuNPgIknhTx1lWFd21/b/0QvXunc8Fm/ck9YNjM/7Nutf+tbZsZHYM9qKDs97O8eNRthx+vhfd4ESM8K3/l4216BstPCd69H1hiYcV7f9JlfDNs8CGb2mrtXDEhX4BhGdzfUbg5RvLtj+GV7DqQH4bY77yI/L5cVazZQUlTIGyvWcurJJ3LlJR/hi9+6g5bWNnKys/j5f97GCceV89xLS7njrgd4/IH/4rY772Lr9l1s3Lqdrdt38cXrP8Et1y3qW3laet8/7TuwesseZj71j8MvVDQ1BJ6eg9c7UXJsOHjUVya+fI9Et19ybHLLAuAHPkNNZL3p2ZA/YejvTNG0EPyTLefBimWFoAcQywwHsMFOWEaywslQv31gelpG3/9/LAvGlIX3PZ/J+BPD/1j1+ndehvjvcVtDONGKl5EXTs4AmvcO3Toumhb+9wEu+RGUf+CgijNU4Bi1P8eN979+v5JVO+qHXqC7K5yFQoj68V0DEM4ieLuviyeWwayJuXzrH04M/4wWC/+M6Zlh+Z7maXdHOJPNKYGsTMjM4+1te/jTM88SM6e+tZvn//JR0q2bP734Kl+/44f85q5/D1+ezDwYMwUy8lizYSt//suLNDQ1c8KJJ/C5axaRMWZiOMs0C1/AfVugYCKkR08D7e4MB4e0WOgGyC0JzeKcIsDCF9K7IbsQ2pqgJg2+tCqcFa5+LOqWaQ7rKD8znPH1qN0GW/8Oddug4lqoWhPqP2leOPtPzw5nWWmxsHx7c2ix1G6DMZPD2XNu1CrZ8lLYf3VRV+Dp1/Xl62gJLZXpHwz1jFe7FXatCGdeL98FE2eHs/UZH4HFnwj//J/8TTjb3/JXqNse0iwtHAAmzIRYRkif90+QPaZv3c01sPK3oT6Ne8KZ67T3w843Yfaloex718H218NnPmZqOJsvmgqlc0KL4z3nQlpa2E/pWeGz3PBsOHCUnRa2s+1VKJkOeePCdlb8NpQve0zY39UbwlnsiReHz6u1dv8zyz2rw74vnQuVS+GEC8I+yBsfzlSP/whs/EvID7Dxz+FsPZYRunFWPBLWWzgprHfDn+G4BaFFWTg5bK+5JrRQIXwniqaGA1rhZGjaG1q0k0+LytodPqfsMTDuhL7WUndXqOfedbD03nBmn1MMZ3wu/M3MDd/JP9watjXtTCguh2XRo+LP/HLY52PKwsEyMz/6HhP2WXo2zL8h1LVhR2jdrH0y1GPuP8Gx50LxdBh3HGz+awgeZaeH/dBcE747G58L37NY3CGzekMo+/jjw/SOZaGFNfefwjq6OvoCUVsDzPsfsHNZaHVljwl5y04PaRm54buansUA214J/2vdXX3fGwjdVxufg7KKUJ/3nBP2077NMOX0ges5hNTiIIHAASEAxDLDh9UR9SOmZ4fp2MAL42ZNKuRbH52dUPluu+028vPzWbFiBeeeey5XX301ANu2beOWW25h3bp1mBkdHR2sWbOG5557jjvuuIPHH3+c2267jYyMDL7xjW8AMHPmTJ5++mnKysoS2naiEmqhiciIohbHMBI9wAPhTH3XW+EMMW/cIS9LXl5e7/t/+7d/49xzz2XJkiVs3ryZc845Z9A8WVl9ZymxWIzOznfeNSUiMhQFjmSlpYem/7twbUNdXR2TJ08G4Be/+EXKtycikgj9HPdgvEsXxH31q1/la1/7Gh/4wAfo6krip50iIimkMQ5JiPaXyOgz1BiHWhwiIpIUBQ4REUmKAoeIiCRFgUNERJKiwCEiIklR4BARkaSkNHCY2QVmttbM1pvZrYPMLzazJWa23MxeMbOT4uZ9wcxWmNlKM/tiXHqJmT1tZuuiv8WprEOqnHPOOTz11FP7pf3gBz/g85///JDL9/yk+KKLLqK2tnbAMrfddht33HHHsNt99NFHWbVq1cEVWkSEFAYOM4sBPwEuBGYBi8xsVr/Fvg4sc/dTgE8BP4zyngTcAMwH5gAXm9mMKM+twDPuPgN4Jpo+6ixatIjFixfvl7Z48WIWLVo0RI4+TzzxBEVFRQe1XQUOEXmnUtnimA+sd/eN7t4OLAYW9ltmFuHgj7uvAcrNbCIwE/i7uze7eyfwF+DSKM9C4P7o/f3Ax1JYh5S54oorePzxx2lrC3fa3bx5Mzt27OBXv/oVFRUVzJ49m29961uD5i0vL2fv3r0AfOc73+GEE07gwx/+MGvXru1d5p577uH0009nzpw5XH755TQ3N/PSSy/x2GOP8ZWvfIW5c+eyYcMGNmzYwAUXXMBpp53GWWedxZo1a1JfeRE5qqXyXlWTgW1x05VAv6eQ8CZwGfCimc0HpgFlwArgO2Y2FmgBLgJ6Lv2e6O47Adx9p5lNGGzjZvYZ4DMAU6dOHb6kT966/xPjDoVjToYLbx9y9tixY5k/fz5/+MMfWLhwIYsXL+bKK6/ka1/7GiUlJXR1dbFgwQKWL1/OKaecMug6XnvtNRYvXswbb7xBZ2cnp556KqedFm7Jfdlll3HDDTcA8M1vfpN7772Xm2++mUsuuYSLL76YK664AoAFCxZw1113MWPGDF5++WU+//nP8+yzzx7afSEiI0oqA8dgN3Tqf3+T24Efmtky4C3gDaDT3Veb2X8ATwONhACT1C1f3f1u4G4ItxxJrujvjp7uqp7Acd999/HQQw9x991309nZyc6dO1m1atWQgeOFF17g0ksvJTc3PJ3ukksu6Z23YsUKvvnNb1JbW0tjYyPnn3/+gPyNjY289NJLfPzjH+9N62kBiYgMJZWBoxKYEjddBuyIX8Dd64FPA5iZAZuiF+5+L3BvNO/fo/UB7Daz0qi1UQr0e0TWQRimZZBKH/vYx/jyl7/M66+/TktLC8XFxdxxxx28+uqrFBcXc80119DaOvxT2GyIGy5ec801PProo8yZM4df/OIXPPfccwOW6e7upqioiGXLlh2C2ojIaJHKMY5XgRlmNt3MMoGrgMfiFzCzomgewPXA81EwoacLysymErqzfh0t9xhwdfT+auB3KaxDSuXn53POOedw7bXXsmjRIurr68nLy2PMmDHs3r2bJ598ctj8Z599NkuWLKGlpYWGhgZ+//vf985raGigtLSUjo4OHnzwwd70goICGhoaACgsLGT69Ok8/PDDALg7b775ZgpqKiIjScoCRzSofRPwFLAaeMjdV5rZjWZ2Y7TYTGClma0h/PrqC3Gr+I2ZrQJ+D/yzu++L0m8HzjOzdcB50fRRa9GiRbz55ptcddVVzJkzh3nz5jF79myuvfZaPvCB4Z8TfOqpp3LllVcyd+5cLr/8cs4666zeed/+9rc544wzOO+88zjxxBN706+66iq+973vMW/ePDZs2MCDDz7Ivffey5w5c5g9eza/+91RG4dF5F2i26pLQrS/REYf3VZdREQOCQUOERFJyqgOHKOhm+5Q0H4SkXijNnBkZ2dTXV2tg+IBuDvV1dVkZ2cf7qKIyBEilddxHNHKysqorKykqqrqcBfliJednU1ZWdnhLoaIHCFGbeDIyMhg+vTph7sYIiJHnVHbVSUiIgdHgUNERJKiwCEiIklR4BARkaQocIiISFIUOEREJCkKHCIikhQFDhERSYoCh4iIJEWBQ0REkqLAISIiSVHgEBGRpChwiIhIUhQ4REQkKQocIiKSFAUOERFJigKHiIgkRYFDRESSosAhIiJJUeAQEZGkpDRwmNkFZrbWzNab2a2DzC82syVmttzMXjGzk+LmfcnMVprZCjP7tZllR+m3mdl2M1sWvS5KZR1ERGR/KQscZhYDfgJcCMwCFpnZrH6LfR1Y5u6nAJ8CfhjlnQzcAlS4+0lADLgqLt/33X1u9HoiVXUQEZGBUtnimA+sd/eN7t4OLAYW9ltmFvAMgLuvAcrNbGI0Lx3IMbN0IBfYkcKyiohIglIZOCYD2+KmK6O0eG8ClwGY2XxgGlDm7tuBO4CtwE6gzt3/GJfvpqh76z4zKx5s42b2GTNbamZLq6qqDk2NREQkpYHDBknzftO3A8Vmtgy4GXgD6IyCwUJgOjAJyDOzT0Z5fgocC8wlBJU7B9u4u9/t7hXuXjF+/Ph3WBUREemRnsJ1VwJT4qbL6Nfd5O71wKcBzMyATdHrfGCTu1dF834LvB/4pbvv7slvZvcAj6ewDiIi0k8qWxyvAjPMbLqZZRIGtx+LX8DMiqJ5ANcDz0fBZCvwXjPLjQLKAmB1lKc0bhWXAitSWAcREeknZS0Od+80s5uApwi/irrP3Vea2Y3R/LuAmcADZtYFrAKui+a9bGaPAK8DnYQurLujVX/XzOYSur02A59NVR1ERGQgc+8/7DDyVFRU+NKlSw93MUREjipm9pq7V/RP15XjIiKSFAUOERFJigKHiIgkRYFDRESSosAhIiJJUeAQEZGkKHCIiEhSFDhERCQpChwiIpIUBQ4REUmKAoeIiCRFgUNERJKiwCEiIklR4BARkaQocIiISFIUOEREJCkKHCIikhQFDhERSYoCh4iIJEWBQ0REknLAwGFmF5uZAoyIiACJtTiuAtaZ2XfNbGaqCyQiIke2AwYOd/8kMA/YAPzczP5mZp8xs4KUl05ERI44CXVBuXs98BtgMVAKXAq8bmY3p7BsIiJyBEpkjOOjZrYEeBbIAOa7+4XAHOBfUlw+ERE5wqQnsMzHge+7+/Pxie7ebGbXpqZYIiJypEqkq+pbwCs9E2aWY2blAO7+zHAZzewCM1trZuvN7NZB5heb2RIzW25mr5jZSXHzvmRmK81shZn92syyo/QSM3vazNZFf4sTrKuIiBwCiQSOh4HuuOmuKG1YZhYDfgJcCMwCFpnZrH6LfR1Y5u6nAJ8CfhjlnQzcAlS4+0lAjPDrLoBbgWfcfQbwTDQtIiLvkkQCR7q7t/dMRO8zE8g3H1jv7hujPIuBhf2WmUU4+OPua4ByM5vYs10gx8zSgVxgR5S+ELg/en8/8LEEyiIiIodIIoGjyswu6Zkws4XA3gTyTQa2xU1XRmnx3gQui9Y7H5gGlLn7duAOYCuwE6hz9z9GeSa6+06A6O+EBMoiIiKHSCKB40bg62a21cy2Af8KfDaBfDZImvebvh0oNrNlwM3AG0BnNG6xEJgOTALyzOyTCWyzb+PhWpOlZra0qqoqmawiIjKMA/6qyt03AO81s3zA3L0hwXVXAlPipsvo627qWXc98GkAMzNgU/Q6H9jk7lXRvN8C7wd+Cew2s1J332lmpcCeIcp9N3A3QEVFRf+AlTJd3U6aQbdDLM3o7nbS0kIMbevsYlddK+Pys8hKT2NvYztdHoq2t6GNlo4uinMzaWjtoKK8hPrWDmoa29lR28KEwizGF2TT3N5J6Zic3u3trGuhKCeTnMxYT71p6eiipqmdyUU5dHU7nd1OU1tnb9TOyYixZlc9NU0dFOdmMLO0kC53Glo7mViQxZ/XVlHb3M6FJ5eSnZ7G9toWapraOWZMNjVN7TS0dlKUm0FWeoyOrm6On1jA61v30d3tTB2bS3ZGjOz0GN3u7GtuZ3x+FjvrWtla00xXtzOhMAt3OPGYAjq6wv5KM2P1rnoKszMYm59JeloaO+ta2NvYzvRxeWza28iYnAymj8tnY1UjWekxHKe2uYOSvEy6up2Orm7MoKqhnS3VTZw3ayIZ6Wk0tnZS19LB2l0NmMHsSWOYPi6Ptbsa2N3QSvnYPLq6u3l9ay3j87M44ZgCsjNidHZ1U9XYxowJBazaWU9hdjpFuZksr6ylKDeTaSW57Glo47gJ+b3bb+noIi8znbqWDorzMmht76bbnab2TjbvbWZqSW5YJivG2l0NTCnJpaw4hzW7Gpg0JoeXN1Uzb0oxjW2d1La0YxiFOek0t3cxq7SQ7bUtFGZnkJsVo72zm7qWDh55rZLzZk1kX1M7u+pbKSvOZWZpAcu31ZGbFeOM6WOpamhj9c565k0tIi8rnc4uZ+mWGqaW5FKUk8kb2/ZRVpxDRiyNTXubyExPY+X2ei446RgaWjspK8mhvqWDnIwYf91QTUaacWJpIZX7mpk7pYiC7AzaO7t5ZvVuJhRmM6Ukh8LsDFbtrGd8fhZd3U7lvhbau7rIzUxnTlkRmelpNLV38vauBmZMKGBTdRPFuRlMG5sHQG1zO9kZMVbuqOOEYwppbutkbH4WsbS+c1J3p7m9i7ysdFrau8hMT6Ozu5vMWBqNbZ3kZ6Xzl7ermFNWRHFeJpv3NtHY1snsSYXsaWijurGd4ybkA7C8spatNc2cNWM8TW3hO3PshHwaWjvYsKeJ7Iw00mNp7GtuJycjRlFuBhmxNDLS0jCDCYVZ1LV0kGZGmhkF2WE/721so7Gts/d/5elVuzl+YgENrR2My8+ivrWD8QVZjMnJYGddKy3tXYwvyKLbnaqGNgqyM6hr6WDZ1n184oxp7GloZWt1MwAnlY0hM5bGnvo21u1poKOrmw8eP4HllbX85e0qxuZnce0HygmH10PH3A98TDWzfwBmA9lxH9j/PkCedOBtYAGwHXgV+IS7r4xbpghodvd2M7sBOMvdP2VmZwD3AacDLcAvgKXu/iMz+x5Q7e63R7/UKnH3rw5XloqKCl+6dOkB63kgexpaWbmjnk1VTWzc20hdSycrd9SRn5XO1JJc9ja28feNNf32A7jDzNJCtu9rpr618x2XIzM9NBSnFOewoappv3mxNKOrO3ymRbkZ1DZ3HPR28rPSaWx75+WNL5OMTAVZ6TQcgu8KhBOKDVWNdHQN/p0pycukpql9v7TJRTnsqGthuMPZtLG5bIkOuGPzMqmOW8e4/Ez2NrYPlfWo9uNPzOPiUyYdVF4ze83dK/qnH7DFYWZ3EQanzwV+BlxB3M9zh+LunWZ2E/AU4VdR97n7SjO7MZp/FzATeMDMuoBVwHXRvJfN7BHgdaCT0IV1d7Tq24GHzOw6whjIxw9Ulneiq9v59uOreHjpNprau4Zcbnll3aDpPV/k1TvrB8w7dWoRtc0dbNzbRGYsjfauvh+vXXTyMRRkZfB/l4ZhosvmTea3b2wHYHx+FlkZaYzLz6KsOJd9ze0sr6xjVmkhW6qbestZnJtJZ5cPOPhPLsphe20LAMdPDGdb08bmUZCVTlVjGy+sC0NYU0tyWb2rnkvmTKIkL5NtNS2s2lHH8ccUMLO0kKa2Tl7dvI+t1U1cdHIpL2+qYWtNM8dPzKezyykfl0duZowJBdnsa24nlmZsrWmmdEw2k4py2FrdzCuba5hYmMWx4/N5fPlOzp4xDoAt1c3E0owrT59CfUsHsbQ0vv+nt/f7hz9/9kTmTCmiu9t5csUuCrLTae3o5rRpxTz/dhUnTx7Da1v39R4s5pSNocudfU0d7K5vZWpJ2Hdtnd28/9hxVDW0UpKXSVFuJu8Zl8eOuhbqWzsZk5NBQVb4V1m1s566lg4KszOYNamQ0jHZvLG1lu21LcydEs6im9s6WbplH3OnFJGbGeOlDdWcNGkM55wwnuXb69hV10p7Zzfzp5fw1/V7ae3spq65nfNPOoaXoxOPPQ1t1DW3M396CQAnlhZS29zB6p31rNheR3VTOwVZ6Xx41kSOHZ9HY1sXu+paeHbNHs6aMZ6ZpQWUj8vj1t+8RVlxDg2tneRlxZhVWshb2+uYUJBNesx4dXMNp5eXkJ5mvO/Yseyub2NLdTObq5s4vTxse1x+Jp3dTnFuBrG0NLbVNFOUm8Erm2p4z/g8qhvbaWrvYkt1ExMKQutiQkE2expa2VDVxOSiHCr3NTNjYgFj8zI5c8Y4tu9rCa3A3Q0YoYW+akc9ZuGzHypoAGRHJ07paUYszWjr7GZCYRbTxuZSua+F+tbQMmpo7eSSuZPYVtNMYXYGG6oamVKSw5TiXI4pzKamuZ3G1vBZZcTSKB2Tzbj8LM6cMY5JY7JxQplyMmOcedw4Xtlcw69e3srZM8YzsTCb0jHZxNKMnXUt/G7ZDnIyY8ybUsT4giyeeGsX22tbuOK0MgqzM3htSw0ZsTQKczJ4bcs+3n/sWCYUZPHW9jrmTimmobWDF9bt5aYPHUduZozHl+/k2TV7OGN6CS9vqmF+eQntXaElNW9aEWt2NlDT1M7JZWOobmxja01LbyuqfGwuGbE0LjjpGNbvaeT82ccMuS8P1gFbHGa23N1PifubD/zW3T9yyEuTIu+kxbHwxy/yZhQU0tOMDx4/ns+feyzj8rN4Yd1exuVn8cHjx7N2dwOTi3IYm5fZ2zUVz91p6+wmlmY0t3cxJifjHdWpv65u368J3198l1nPdE1zO+PyswYs29DaQV5m+qD1OBB3P+TNYhmoO2rBHcxndDTo7OomPdY3BNv/+yvvjoNucQCt0d9mM5sEVBMGrUe85vZO3qysY0JBFn/5yrmYQXZGrHd+T18swNwpRcOuy8x6847JOfR3qR8uaMDAA0xamg0aNAAKsg8+qClovDtG+kE0PmjAyK/v0SaRwPH7aCzie4SuIwfuSWWhjhRVDW0AfPWCE3sHn0VERrthA0f0AKdn3L0W+I2ZPQ5ku/vgHfojzJ4ocIwvGPzMXERkNBq2z8Tdu4E746bbRkvQAGiKBpXzsxJpmImIjA6JdLb/0cwut1HYed3zs4HRV3MRkaElcir9ZSCPcEV3K+GKcHf3wpSW7EgQRQ7FDRGRPolcOT5qHxHrUeQYhY0tEZEhJXIB4NmDpfd/sNNIprAhItInka6qr8S9zybcLv014EMpKdERJIG7sYiIjDqJdFV9NH7azKYA301ZiY4gPYFDPVUiIn0O5hLmSuCkAy41AvT+qkqdVSIivRIZ4/gRfcfQNGAu4QFMo4ZaHCIifRIZ44i/O2An8Gt3/2uKynNESeSW8yIio00igeMRoNXduwDMLGZmue7enNqiHX4KGyIiAyUyxvEMkBM3nQP8KTXFObJocFxEZKBEAke2uzf2TETvc1NXpCNJdAGgBsdFRHolEjiazOzUngkzO43wONdRQy0OEZE+iYxxfBF42Mx2RNOlwJUpK9ERRGPjIiIDJXIB4KtmdiJwAuHuG2vcvSPlJTsC6O64IiIDHbCrysz+Gchz9xXu/haQb2afT33RDr/ewXGNcYiI9EpkjOOG6AmAALj7PuCGlJXoCKQWh4hIn0QCR1r8Q5zMLAZkpq5IRw7XlRwiIgMkMjj+FPCQmd1F6Pa/EXgypaU6Qrge5CQiMkAigeNfgc8AnyMcQ98g/LJqxNPguIjIQAfsqnL3buDvwEagAlgArE5xuY4IffeqUuQQEekxZIvDzI4HrgIWAdXA/wVw93PfnaIdOdTiEBHpM1xX1RrgBeCj7r4ewMy+9K6USkREjljDdVVdDuwC/mxm95jZApLsszGzC8xsrZmtN7NbB5lfbGZLzGy5mb1iZidF6SeY2bK4V72ZfTGad5uZbY+bd1EyZUqGBsdFRAYassXh7kuAJWaWB3wM+BIw0cx+Cixx9z8Ot+LoZ7s/Ac4jPDXwVTN7zN1XxS32dWCZu18aXZ3+E2CBu68lPDCqZz3bgSVx+b7v7nckVdOD0PNzXFNflYhIr0QGx5vc/UF3vxgoA5YBA1oPg5gPrHf3je7eDiwGFvZbZhbhtu24+xqg3Mwm9ltmAbDB3bcksM2UUNgQEemT1DPH3b3G3f8/d/9QAotPBrbFTVdGafHeBC4DMLP5wDRCcIp3FfDrfmk3Rd1b95lZ8WAbN7PPmNlSM1taVVWVQHEH0k0ORUQGSipwJGmwE/X+h+LbgWIzWwbcTLhGpLN3BWaZwCXAw3F5fgocS+jK2gncOdjG3f1ud69w94rx48cfVAX0ICcRkYESuQDwYFUCU+Kmy4Ad8Qu4ez3waYDotiabolePC4HX3X13XJ7e92Z2D/D4IS95z7Z6tqPOKhGRXqlscbwKzDCz6VHL4SrgsfgFzKwomgdwPfB8FEx6LKJfN5WZxV+1fimw4pCXPNJzAaBaHCIifVLW4nD3TjO7iXCvqxhwn7uvNLMbo/l3ATOBB8ysC1gFXNeT38xyCb/I+my/VX/XzOYSGgSbB5kvIiIplMquKtz9CeCJfml3xb3/GzBjiLzNwNhB0v/HIS7mkDQ2LiIyUCq7qo5+GhwXERlAgWMYugBQRGQgBY4EKGyIiPRR4BiGLgAUERlIgWMYepCTiMhAChzD6Ls7riKHiEgPBY5h9A2OH+aCiIgcQRQ4EqC4ISLSR4FjGBocFxEZSIFjGL1xQ00OEZFeChzD6bnJoSKHiEgvBY4EaHBcRKSPAscwNMQhIjKQAscw+q7jEBGRHgocw+h7kJNCh4hIDwWOYfQ9OlZERHoocCRADQ4RkT4KHMPQBYAiIgMpcAyjr6tKTQ4RkR4KHMNw/axKRGQABY4EaIxDRKSPAoeIiCRFgWMY6qkSERlIgWMYfQ9yUugQEemhwDEMtThERAZS4EiAGhwiIn1SGjjM7AIzW2tm683s1kHmF5vZEjNbbmavmNlJUfoJZrYs7lVvZl+M5pWY2dNmti76W5yq8uv6PxGRgVIWOMwsBvwEuBCYBSwys1n9Fvs6sMzdTwE+BfwQwN3Xuvtcd58LnAY0A0uiPLcCz7j7DOCZaDol+rqq1OQQEemRyhbHfGC9u29093ZgMbCw3zKzCAd/3H0NUG5mE/stswDY4O5boumFwP3R+/uBj6Wg7ED84HiqtiAicvRJZeCYDGyLm66M0uK9CVwGYGbzgWlAWb9lrgJ+HTc90d13AkR/Jwy2cTP7jJktNbOlVVVVB10JERHZXyoDx2Dn6f2HDW4His1sGXAz8AbQ2bsCs0zgEuDhZDfu7ne7e4W7V4wfPz7Z7NE6DiqbiMiIlp7CdVcCU+Kmy4Ad8Qu4ez3waQALF0tsil49LgRed/fdcWm7zazU3XeaWSmwJxWFj6euKhGRPqlscbwKzDCz6VHL4SrgsfgFzKwomgdwPfB8FEx6LGL/biqidVwdvb8a+N0hL3mk9wmAGhwXEemVshaHu3ea2U3AU0AMuM/dV5rZjdH8u4CZwANm1gWsAq7ryW9mucB5wGf7rfp24CEzuw7YCnw8dXXoKUuqtiAicvRJZVcV7v4E8ES/tLvi3v8NmDFE3mZg7CDp1YRfWr1rFDdERProyvFhaGxcRGQgBY5h9HVVqc0hItJDgWMYvRcAHuZyiIgcSRQ4EqAGh4hIHwWOYegCQBGRgRQ4htETNzTGISLSR4FjOGpyiIgMoMAxDEfjGyIi/SlwHIDihojI/hQ4hqGeKhGRgRQ4huG4BsZFRPpR4BiGu7qqRET6U+A4ADU4RET2p8AxDA1xiIgMpMAxjNBVpSaHiEg8BY5hOBrkEBHpT4FjOIobIiIDKHAcgAbHRUT2p8AxDA2Oi4gMpMAxDHfX4LiISD8KHMNwV1eViEh/ChwHoLghIrI/BY5haIxDRGQgBY5hhK4qtTlEROIpcAzDcXVViYj0o8AxDHc0yCEi0k9KA4eZXWBma81svZndOsj8YjNbYmbLzewVMzspbl6RmT1iZmvMbLWZvS9Kv83MtpvZsuh1UUrrkMqVi4gchdJTtWIziwE/Ac4DKoFXzewxd18Vt9jXgWXufqmZnRgtvyCa90PgD+5+hZllArlx+b7v7nekquwiIjK0VLY45gPr3X2ju7cDi4GF/ZaZBTwD4O5rgHIzm2hmhcDZwL3RvHZ3r01hWQflricAioj0l8rAMRnYFjddGaXFexO4DMDM5gPTgDLgPUAV8HMze8PMfmZmeXH5boq6t+4zs+LBNm5mnzGzpWa2tKqq6qAq4OgCQBGR/lIZOAY75Pa/NOJ2oNjMlgE3A28AnYQutFOBn7r7PKAJ6Bkj+SlwLDAX2AncOdjG3f1ud69w94rx48cf0kqIiIxmKRvjILQwpsRNlwE74hdw93rg0wAW+oQ2Ra9coNLdX44WfYQocLj77p78ZnYP8HiKyh9+VSUiIvtJZYvjVWCGmU2PBrevAh6LXyD65VRmNHk98Ly717v7LmCbmZ0QzVsArIrylMat4lJgRaoq4GiMQ0Skv5S1ONy908xuAp4CYsB97r7SzG6M5t8FzAQeMLMuQmC4Lm4VNwMPRoFlI1HLBPiumc0ldHttBj6bqjqcNGkMHZ1qdoiIxDMfBf0xFRUVvnTp0sNdDBGRo4qZvebuFf3TdeW4iIgkRYFDRESSosAhIiJJUeAQEZGkKHCIiEhSFDhERCQpChwiIpIUBQ4REUnKqLgA0MyqgC0HmX0csPcQFudooDqPDqrz6PBO6jzN3QfcJXZUBI53wsyWDnbl5EimOo8OqvPokIo6q6tKRESSosAhIiJJUeA4sLsPdwEOA9V5dFCdR4dDXmeNcYiISFLU4hARkaQocIiISFIUOIZhZheY2VozW29mtx7u8hwKZjbFzP5sZqvNbKWZfSFKLzGzp81sXfS3OC7P16J9sNbMzj98pX9nzCxmZm+Y2ePR9Iiuc/Ro5kfMbE30eb9vFNT5S9H3eoWZ/drMskdanc3sPjPbY2Yr4tKSrqOZnWZmb0Xz/suSeU62u+s1yIvwuNsNwHuATOBNYNbhLtchqFcpcGr0vgB4G5gFfBe4NUq/FfiP6P2sqO5ZwPRon8QOdz0Osu5fBn4FPB5Nj+g6A/cD10fvM4GikVxnYDKwCciJph8CrhlpdQbOBk4FVsSlJV1H4BXgfYABTwIXJloGtTiGNh9Y7+4b3b0dWAwsPMxlesfcfae7vx69bwBWE/7hFhIONER/Pxa9Xwgsdvc2d98ErCfsm6OKmZUB/wD8LC55xNbZzAoJB5h7Ady93d1rGcF1jqQDOWaWDuQCOxhhdXb354GafslJ1dHMSoFCd/+bhyjyQFyeA1LgGNpkYFvcdGWUNmKYWTkwD3gZmOjuOyEEF2BCtNhI2Q8/AL4KdMeljeQ6vweoAn4edc/9zMzyGMF1dvftwB3AVmAnUOfuf2QE1zlOsnWcHL3vn54QBY6hDdbfN2J+u2xm+cBvgC+6e/1wiw6SdlTtBzO7GNjj7q8lmmWQtKOqzoQz71OBn7r7PKCJ0IUxlKO+zlG//kJCl8wkIM/MPjlclkHSjqo6J2CoOr6juitwDK0SmBI3XUZo9h71zCyDEDQedPffRsm7o+Yr0d89UfpI2A8fAC4xs82ELscPmdkvGdl1rgQq3f3laPoRQiAZyXX+MLDJ3avcvQP4LfB+RnadeyRbx8roff/0hChwDO1VYIaZTTezTOAq4LHDXKZ3LPrlxL3Aanf/z7hZjwFXR++vBn4Xl36VmWWZ2XRgBmFQ7ajh7l9z9zJ3Lyd8js+6+ycZ2XXeBWwzsxOipAXAKkZwnQldVO81s9zoe76AMIY3kuvcI6k6Rt1ZDWb23mhffSouz4Ed7l8IHMkv4CLCr442AN843OU5RHU6k9AkXQ4si14XAWOBZ4B10d+SuDzfiPbBWpL45cWR+ALOoe9XVSO6zsBcYGn0WT8KFI+COv8vYA2wAvhvwq+JRlSdgV8TxnA6CC2H6w6mjkBFtJ82AD8mupNIIi/dckRERJKirioREUmKAoeIiCRFgUNERJKiwCEiIklR4BARkaQocIgcAmbWZWbL4l6H7G7KZlYefydUkcMt/XAXQGSEaHH3uYe7ECLvBrU4RFLIzDab2X+Y2SvR67gofZqZPWNmy6O/U6P0iWa2xMzejF7vj1YVM7N7omdN/NHMcg5bpWTUU+AQOTRy+nVVXRk3r97d5xOuzv1BlPZj4AF3PwV4EPivKP2/gL+4+xzCvaVWRukzgJ+4+2ygFrg8pbURGYauHBc5BMys0d3zB0nfDHzI3TdGN5fc5e5jzWwvUOruHVH6TncfZ2ZVQJm7t8Wtoxx42t1nRNP/CmS4+/95F6omMoBaHCKp50O8H2qZwbTFve9C45NyGClwiKTelXF//xa9f4lwp16AfwJejN4/A3wOep+RXvhuFVIkUTprETk0csxsWdz0H9y95ye5WWb2MuFEbVGUdgtwn5l9hfCkvk9H6V8A7jaz6wgti88R7oQqcsTQGIdICkVjHBXuvvdwl0XkUFFXlYiIJEUtDhERSYpaHCIikhQFDhERSYoCh4iIJEWBQ0REkqLAISIiSfn/AfcVK385A7ccAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416748454421152\n"
     ]
    }
   ],
   "source": [
    "predicts = model_nn.predict(test_X1[features_nn], batch_size=1024, use_multiprocessing=True)\n",
    "predicts = np.where(predicts < 0.5, 0, 1)\n",
    "print(f1_score(test_Y, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "386/386 [==============================] - 3s 6ms/step - loss: 0.0806 - binary_accuracy: 0.9686 - val_loss: 0.0131 - val_binary_accuracy: 0.9964\n",
      "Epoch 2/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0108 - binary_accuracy: 0.9968 - val_loss: 0.0099 - val_binary_accuracy: 0.9978\n",
      "Epoch 3/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0061 - binary_accuracy: 0.9983 - val_loss: 0.0086 - val_binary_accuracy: 0.9982\n",
      "Epoch 4/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0050 - binary_accuracy: 0.9986 - val_loss: 0.0090 - val_binary_accuracy: 0.9983\n",
      "Epoch 5/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0044 - binary_accuracy: 0.9987 - val_loss: 0.0093 - val_binary_accuracy: 0.9983\n",
      "Epoch 6/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0040 - binary_accuracy: 0.9988 - val_loss: 0.0088 - val_binary_accuracy: 0.9984\n",
      "Epoch 7/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0039 - binary_accuracy: 0.9988 - val_loss: 0.0093 - val_binary_accuracy: 0.9982\n",
      "Epoch 8/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0035 - binary_accuracy: 0.9989 - val_loss: 0.0095 - val_binary_accuracy: 0.9984\n",
      "Epoch 9/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0035 - binary_accuracy: 0.9990 - val_loss: 0.0091 - val_binary_accuracy: 0.9983\n",
      "Epoch 10/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0035 - binary_accuracy: 0.9990 - val_loss: 0.0093 - val_binary_accuracy: 0.9983\n",
      "Epoch 11/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0033 - binary_accuracy: 0.9990 - val_loss: 0.0085 - val_binary_accuracy: 0.9984\n",
      "Epoch 12/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0031 - binary_accuracy: 0.9991 - val_loss: 0.0092 - val_binary_accuracy: 0.9984\n",
      "Epoch 13/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0032 - binary_accuracy: 0.9990 - val_loss: 0.0103 - val_binary_accuracy: 0.9983\n",
      "Epoch 14/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0030 - binary_accuracy: 0.9992 - val_loss: 0.0108 - val_binary_accuracy: 0.9984\n",
      "Epoch 15/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0030 - binary_accuracy: 0.9991 - val_loss: 0.0105 - val_binary_accuracy: 0.9984\n",
      "Epoch 16/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0030 - binary_accuracy: 0.9991 - val_loss: 0.0110 - val_binary_accuracy: 0.9984\n",
      "Epoch 17/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0028 - binary_accuracy: 0.9991 - val_loss: 0.0123 - val_binary_accuracy: 0.9983\n",
      "Epoch 18/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0029 - binary_accuracy: 0.9991 - val_loss: 0.0120 - val_binary_accuracy: 0.9984\n",
      "Epoch 19/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0028 - binary_accuracy: 0.9992 - val_loss: 0.0116 - val_binary_accuracy: 0.9984\n",
      "Epoch 20/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0028 - binary_accuracy: 0.9992 - val_loss: 0.0109 - val_binary_accuracy: 0.9983\n",
      "Epoch 21/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0028 - binary_accuracy: 0.9992 - val_loss: 0.0104 - val_binary_accuracy: 0.9984\n",
      "Epoch 22/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0027 - binary_accuracy: 0.9992 - val_loss: 0.0108 - val_binary_accuracy: 0.9984\n",
      "Epoch 23/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0028 - binary_accuracy: 0.9992 - val_loss: 0.0102 - val_binary_accuracy: 0.9984\n",
      "Epoch 24/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0027 - binary_accuracy: 0.9992 - val_loss: 0.0119 - val_binary_accuracy: 0.9983\n",
      "Epoch 25/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0026 - binary_accuracy: 0.9992 - val_loss: 0.0119 - val_binary_accuracy: 0.9985\n",
      "Epoch 26/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0027 - binary_accuracy: 0.9992 - val_loss: 0.0134 - val_binary_accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0026 - binary_accuracy: 0.9992 - val_loss: 0.0121 - val_binary_accuracy: 0.9984\n",
      "Epoch 28/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0025 - binary_accuracy: 0.9993 - val_loss: 0.0138 - val_binary_accuracy: 0.9982\n",
      "Epoch 29/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0024 - binary_accuracy: 0.9993 - val_loss: 0.0166 - val_binary_accuracy: 0.9984\n",
      "Epoch 30/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0026 - binary_accuracy: 0.9992 - val_loss: 0.0142 - val_binary_accuracy: 0.9984\n",
      "Epoch 31/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0025 - binary_accuracy: 0.9993 - val_loss: 0.0154 - val_binary_accuracy: 0.9983\n",
      "Epoch 32/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0026 - binary_accuracy: 0.9992 - val_loss: 0.0139 - val_binary_accuracy: 0.9984\n",
      "Epoch 33/100\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.0025 - binary_accuracy: 0.9992 - val_loss: 0.0149 - val_binary_accuracy: 0.9983\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "model_nn = ModelCreate((train_X1.shape[1],))\n",
    "history = model_nn.fit(train_X1, train_Y, batch_size=1024, validation_split=0.2, epochs=100, callbacks=[callback], use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9500332999985386\n"
     ]
    }
   ],
   "source": [
    "predicts = model_nn.predict(test_X1, batch_size=1024, use_multiprocessing=True)\n",
    "predicts = np.where(predicts < 0.5, 0, 1)\n",
    "print(f1_score(test_Y, predicts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47bdff014318604fa210da353932788820ee8531c76f980c2092f0fcb79da61a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
