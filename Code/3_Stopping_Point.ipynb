{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'CICIDS_2017'\n",
    "models = ['LR', 'GB', 'NN']\n",
    "individual_methods = ['chi2', 'ANOVA', 'mutualinfo', 'sfs(gb)', 'sfs(lr)', 'im(gb)', 'im(lr)']\n",
    "set_methods = ['union', 'intersection', 'quorum']\n",
    "columns = ['MD_size', 'MD_score', 'MD_test', 'MPR_size', 'MPR_score', 'MPR_test', 'MS_size', 'MS_score', 'MS_test']\n",
    "tolerence = 0.03\n",
    "factor = 0.03"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopping Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxDelta(score):\n",
    "    max_delta = 0\n",
    "    index = len(score) - 1\n",
    "    for i in range(len(score)-1, 0, -1):\n",
    "        delta = score[i] - score[i-1]\n",
    "        if delta > max_delta:\n",
    "            max_delta = delta\n",
    "            index = i\n",
    "\n",
    "    return index\n",
    "\n",
    "def MinPerfReq(score, tolerence=0.03):\n",
    "    best_score = score[-1] * (1 - tolerence)\n",
    "    index = len(score) - 1\n",
    "    for i in range(len(score)-1, 0, -1):\n",
    "        if score[i] < best_score:\n",
    "            index = i+1\n",
    "            break\n",
    "\n",
    "    return index\n",
    "\n",
    "def MaxScore(score, size, factor=0.03):\n",
    "    best_performance = 0\n",
    "    index = len(score) - 1\n",
    "    for i in range(len(score)-1, 0, -1):\n",
    "        current_size = size[i]\n",
    "        adj_score = score[i] - (factor * current_size)\n",
    "        if adj_score > best_performance:\n",
    "            best_performance = adj_score\n",
    "            index = i\n",
    "\n",
    "    return index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_df = []\n",
    "indices = []\n",
    "for model in models:\n",
    "    # read the results, extract their score parts.\n",
    "    cv_df = pd.read_csv(os.path.join('../Results/', dataset_name, 'Greedy_CV_F1_' + model + '.csv'), index_col=0)\n",
    "    test_df = pd.read_csv(os.path.join('../Results/', dataset_name, 'Greedy_Test_F1_' + model + '.csv'), index_col=0)\n",
    "    cv_score = cv_df.iloc[0].apply(lambda x: float(x.translate( { ord(i): None for i in '()'} ).split(',')[0]))\n",
    "    test_score = test_df.iloc[0]\n",
    "    size = np.arange(1, cv_df.shape[1]+1)\n",
    "    stop1 = MaxDelta(cv_score)\n",
    "    stop2 = MinPerfReq(cv_score, tolerence)\n",
    "    stop3 = MaxScore(cv_score, size, factor)\n",
    "    stop_df.append([stop1+1, cv_score[stop1], test_score[stop1],\n",
    "                    stop2+1, cv_score[stop2], test_score[stop2],\n",
    "                    stop3+1, cv_score[stop3], test_score[stop3],])\n",
    "    indices.append('greedy_' + model)\n",
    "\n",
    "pd.DataFrame(stop_df, index=indices, columns=columns).to_csv(os.path.join('../Results/', dataset_name, 'Greedy_Stopping_Point_2.csv'))\n",
    "\n",
    "stop_df = []\n",
    "indices = []\n",
    "for model in models:\n",
    "    # read the results, extract their score parts.\n",
    "    cv_df = pd.read_csv(os.path.join('../Results/Paper/', dataset_name, 'Greedy_CV_F1_' + model + '.csv'), index_col=0)\n",
    "    test_df = pd.read_csv(os.path.join('../Results/Paper/', dataset_name, 'Greedy_Test_F1_' + model + '.csv'), index_col=0)\n",
    "    cv_score = cv_df.iloc[0].apply(lambda x: float(x.translate( { ord(i): None for i in '()'} ).split(',')[0]))\n",
    "    test_score = test_df.iloc[0]\n",
    "    size = np.arange(1, cv_df.shape[1]+1)\n",
    "    stop1 = MaxDelta(cv_score)\n",
    "    stop2 = MinPerfReq(cv_score, tolerence)\n",
    "    stop3 = MaxScore(cv_score, size, factor)\n",
    "    stop_df.append([stop1+1, cv_score[stop1], test_score[stop1],\n",
    "                    stop2+1, cv_score[stop2], test_score[stop2],\n",
    "                    stop3+1, cv_score[stop3], test_score[stop3],])\n",
    "    indices.append('greedy_' + model)\n",
    "\n",
    "pd.DataFrame(stop_df, index=indices, columns=columns).to_csv(os.path.join('../Results/Paper/', dataset_name, 'Greedy_Stopping_Point_2.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_df = []\n",
    "indices = []\n",
    "size_df = pd.read_csv(os.path.join('../Results/', dataset_name, 'Set_Features.csv'), index_col=0)\n",
    "for model in models:\n",
    "    # read the results, extract their score parts.\n",
    "    cv_df = pd.read_csv(os.path.join('../Results/', dataset_name, 'Set_CV_F1_' + model + '.csv'), index_col=0)\n",
    "    test_df = pd.read_csv(os.path.join('../Results/', dataset_name, 'Set_Test_F1_' + model + '.csv'), index_col=0)\n",
    "    \n",
    "    for method in set_methods:\n",
    "        cv_score = cv_df.loc[method].apply(lambda x: float(x.translate( { ord(i): None for i in '()'} ).split(',')[0]))\n",
    "\n",
    "        test_score = test_df.loc[method]\n",
    "        size = size_df.loc[method+'_size'].apply(lambda x: float(x))\n",
    "\n",
    "        stop1 = MaxDelta(cv_score)\n",
    "        stop2 = MinPerfReq(cv_score)\n",
    "        stop3 = MaxScore(cv_score, size)\n",
    "        stop_df.append([stop1+1, cv_score[stop1], test_score[stop1],\n",
    "                        stop2+1, cv_score[stop2], test_score[stop2],\n",
    "                        stop3+1, cv_score[stop3], test_score[stop3],])\n",
    "        indices.append(method + '_' + model)\n",
    "\n",
    "pd.DataFrame(stop_df, index=indices, columns=columns).to_csv(os.path.join('../Results/', dataset_name, 'Set_Stopping_Point.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_df = []\n",
    "indices = []\n",
    "for model in models:\n",
    "    # read the results, extract their score parts.\n",
    "    cv_df = pd.read_csv(os.path.join('../Results/', dataset_name, 'Individual_CV_F1_' + model + '.csv'), index_col=0)\n",
    "    test_df = pd.read_csv(os.path.join('../Results/', dataset_name, 'Individual_Test_F1_' + model + '.csv'), index_col=0)\n",
    "    for method in individual_methods: \n",
    "        cv_score = cv_df.loc[method].apply(lambda x: float(x.translate( { ord(i): None for i in '()'} ).split(',')[0]))\n",
    "        test_score = test_df.loc[method]\n",
    "        size = np.arange(1, cv_df.shape[1]+1)\n",
    "        stop1 = MaxDelta(cv_score)\n",
    "        stop2 = MinPerfReq(cv_score)\n",
    "        stop3 = MaxScore(cv_score, size)\n",
    "        stop_df.append([stop1+1, cv_score[stop1], test_score[stop1],\n",
    "                        stop2+1, cv_score[stop2], test_score[stop2],\n",
    "                        stop3+1, cv_score[stop3], test_score[stop3],])\n",
    "        indices.append(method + '_' + model)\n",
    "    \n",
    "pd.DataFrame(stop_df, index=indices, columns=columns).to_csv(os.path.join('../Results/', dataset_name, 'Individual_Stopping_Point.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47bdff014318604fa210da353932788820ee8531c76f980c2092f0fcb79da61a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
