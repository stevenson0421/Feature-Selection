{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from tqdm import trange\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82332, 45)\n",
      "(175341, 45)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_raw = pd.read_csv('../Data/UNSW-NB15/train.csv')\n",
    "print(train_raw.shape)\n",
    "test_raw = pd.read_csv('../Data/UNSW-NB15/test.csv')\n",
    "print(test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate label and Drop ID\n",
    "train_X = train_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "train_Y = train_raw['label']\n",
    "test_X = test_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "test_Y = test_raw['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data with min, max of training data\n",
    "test_X1 = (test_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "train_X1 = (train_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "\n",
    "test_X1[test_X1 < 0] = 0\n",
    "test_X1[test_X1 > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(82332, 24)\n",
      "(175341, 24)\n"
     ]
    }
   ],
   "source": [
    "# correlation based feature selection\n",
    "corr = train_X1.corr().abs()\n",
    "\n",
    "threshold = 0.8\n",
    "corr.values[np.tril_indices_from(corr.values)] = np.nan\n",
    "redundant = []\n",
    "for j in corr.columns:\n",
    "    for i in corr.index:\n",
    "        if corr.loc[i, j] > threshold:\n",
    "            redundant.append((i, j))\n",
    "\n",
    "train_X2 = train_X1.copy()\n",
    "train_X2['label'] = train_Y\n",
    "corr2 = train_X2.corr().abs()\n",
    "\n",
    "corr3 = corr2['label'].iloc[:-1].copy()\n",
    "drop = []\n",
    "\n",
    "#! modify\n",
    "for i, j in redundant:\n",
    "    if corr3[i] > corr3[j]:\n",
    "        if j not in drop:\n",
    "            drop.append(j)\n",
    "    elif i not in drop:\n",
    "        drop.append(i)\n",
    "print(drop)\n",
    "\n",
    "train_X1 = train_X1.drop(drop, axis=1)\n",
    "test_X1 = test_X1.drop(drop, axis=1)\n",
    "print(train_X1.shape)\n",
    "print(test_X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dur', 'spkts', 'dpkts', 'rate', 'sttl', 'dttl', 'sload', 'dload',\n",
      "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'synack',\n",
      "       'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_state_ttl',\n",
      "       'ct_dst_sport_ltm', 'ct_ftp_cmd', 'ct_flw_http_mthd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_X1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFECV, SequentialFeatureSelector, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ct_ftp_cmd', 'trans_depth', 'ct_flw_http_mthd', 'response_body_len',\n",
      "       'dtcpb', 'stcpb', 'swin', 'djit', 'spkts', 'sjit', 'ct_dst_sport_ltm',\n",
      "       'sinpkt', 'dpkts', 'synack', 'dload', 'sttl', 'dinpkt', 'dttl', 'dmean',\n",
      "       'dur', 'rate', 'ct_state_ttl', 'sload', 'smean'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# select 1 worse feature iteratively with chi2, ANOVA, mutual info\n",
    "\n",
    "subset_all = []\n",
    "selector = SelectKBest(mutual_info_classif, k='all')\n",
    "selector.fit(train_X1, train_Y)\n",
    "sort_index = np.argsort(selector.scores_)\n",
    "cols = train_X1.columns[sort_index]\n",
    "subset_all.append(cols)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [2:36:50<00:00, 409.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smean', 'dmean', 'dload', 'rate', 'dpkts', 'dinpkt', 'sload', 'ct_state_ttl', 'sttl', 'dur', 'dttl', 'synack', 'djit', 'sinpkt', 'sjit', 'spkts', 'dtcpb', 'response_body_len', 'swin', 'stcpb', 'ct_flw_http_mthd', 'ct_ftp_cmd', 'ct_dst_sport_ltm', 'trans_depth']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# select 1 worst feature iteratively with SFS, using RF, LR\n",
    "cols = []\n",
    "model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "selector = SequentialFeatureSelector(model, n_features_to_select=1, direction='backward', scoring='f1', cv=5, n_jobs=-1)\n",
    "for k in trange(train_X1.shape[1]-1):\n",
    "    selector.fit(train_X1.drop(cols, axis=1), train_Y)\n",
    "    f = train_X1.columns.drop(cols)[selector.get_support()]\n",
    "    cols.append(f[0])\n",
    "cols.append(train_X1.columns.drop(cols)[0])\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_all.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dur', 'ct_dst_sport_ltm', 'ct_state_ttl', 'response_body_len',\n",
      "       'trans_depth', 'dmean', 'smean', 'synack', 'dtcpb', 'stcpb', 'swin',\n",
      "       'djit', 'sjit', 'dinpkt', 'sinpkt', 'dload', 'sload', 'dttl', 'sttl',\n",
      "       'rate', 'dpkts', 'spkts', 'ct_flw_http_mthd', 'ct_ftp_cmd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# select 1 worst feature iteratively with SFS, using RF, LR\n",
    "model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "selector = RFECV(model, scoring='f1', cv=5, n_jobs=-1)\n",
    "selector.fit(train_X1, train_Y)\n",
    "sort_index = np.argsort(selector.ranking_)\n",
    "cols = train_X1.columns[sort_index]\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_all.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:17<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ct_ftp_cmd', 'trans_depth', 'response_body_len', 'dtcpb', 'stcpb', 'swin', 'dttl', 'ct_flw_http_mthd', 'djit', 'spkts', 'sjit', 'dinpkt', 'dpkts', 'sinpkt', 'dload', 'dur', 'ct_dst_sport_ltm', 'dmean', 'rate', 'ct_state_ttl', 'synack', 'sttl', 'smean', 'sload']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "cols = []\n",
    "train_X2 = train_X1.copy()\n",
    "for k in trange(train_X1.shape[1]-1):\n",
    "    model.fit(train_X2, train_Y)\n",
    "    sort_index = np.argsort(model.feature_importances_)\n",
    "    f = train_X2.columns[sort_index[0]]\n",
    "    cols.append(f)\n",
    "    train_X2 = train_X2.drop(f, axis=1)\n",
    "cols.append(train_X1.columns.drop(cols)[0])\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_all.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(subset_all, index=['mi', 'sfs(rf)', 'rfe(rf)', 'im(rf)']).to_csv('../Results/Paper/Feature_sets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure performance by cv(f1 score)\n",
    "cv_times_all = []\n",
    "f1_all = []\n",
    "model = LogisticRegression(max_iter=10000, random_state=0, n_jobs=-1)\n",
    "for i in range(len(subset_all)):\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        # cross validation\n",
    "        second = time.time()\n",
    "        cv = cross_val_score(model, train_X1.drop(subset_all[i][:k+1], axis=1), train_Y, scoring='f1', n_jobs=-1)\n",
    "        second2 = time.time()\n",
    "        cv_times.append(second2 - second)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "    \n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['mi', 'sbs(rf)', 'rfe(rf)', 'im(rf)']\n",
    "pd.DataFrame(cv_times_all, index=methods).to_csv('../Results/Paper/Time_LR.csv')\n",
    "pd.DataFrame(f1_all, index=methods).to_csv('../Results/Paper/F1_LR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Logistic Regression', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[1,:,0], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[2,:,0], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[3,:,0], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[1], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[2], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[3], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=0)\n",
    "for i in range(len(subset_all)):\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        # cross validation\n",
    "        second = time.time()\n",
    "        cv = cross_val_score(model, train_X1.drop(subset_all[i][:k+1], axis=1), train_Y, scoring='f1', n_jobs=-1)\n",
    "        second2 = time.time()\n",
    "        cv_times.append(second2 - second)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "    \n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all, index=methods).to_csv('../Results/Paper/Time_GB.csv')\n",
    "pd.DataFrame(f1_all, index=methods).to_csv('../Results/Paper/F1_GB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Logistic Regression', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[1,:,0], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[2,:,0], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[3,:,0], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[1], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[2], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[3], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential, layers, optimizers, losses, metrics, callbacks\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCreate(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "\n",
    "kf = StratifiedKFold(shuffle=True, random_state=0)\n",
    "callback = callbacks.EarlyStopping(patience=3, min_delta=0.1, restore_best_weights=True)\n",
    "for i in range(len(subset_all)):\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]-1, 0, -1):\n",
    "        model = ModelCreate((k,))\n",
    "        # cross validation\n",
    "        j = 0\n",
    "        cv_time = 0\n",
    "        cv = np.zeros(shape=5)\n",
    "        train_X2 = train_X1.drop(subset_all[i][:k+1], axis=1).copy()\n",
    "        for train_index, test_index in kf.split(train_X2, train_Y):\n",
    "            x_train_fold, x_test_fold = train_X2.iloc[train_index, :], train_X2.iloc[test_index, :]\n",
    "            y_train_fold, y_test_fold = train_Y.iloc[train_index], train_Y.iloc[test_index]\n",
    "\n",
    "            second = time.time()\n",
    "            model.fit(x_train_fold.values, y_train_fold.values, validation_data=(x_test_fold, y_test_fold), epochs=30, callbacks=[callback], use_multiprocessing=True, verbose=0)\n",
    "            predict = model.predict(x_test_fold, use_multiprocessing=True)\n",
    "            predict = np.where(predict < 0.5, 0, 1)\n",
    "            cv[j] = f1_score(y_test_fold, predict)\n",
    "            second2 = time.time()\n",
    "            cv_time += second2 - second\n",
    "            j += 1\n",
    "        cv_times.append(cv_time)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "    \n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all, index=methods).to_csv('../Results/Paper/Time_DNN.csv')\n",
    "pd.DataFrame(f1_all, index=methods).to_csv('../Results/Paper/F1_DNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Logistic Regression', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[1,:,0], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[2,:,0], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), np.array(f1_all)[3,:,0], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[1], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[2], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1], 0, -1), cv_times_all[3], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47bdff014318604fa210da353932788820ee8531c76f980c2092f0fcb79da61a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
