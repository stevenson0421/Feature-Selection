{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from tqdm import trange\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_raw = pd.read_csv('../../Data/UNSW-NB15/train.csv')\n",
    "print(train_raw.shape)\n",
    "test_raw = pd.read_csv('../../Data/UNSW-NB15/test.csv')\n",
    "print(test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate label and Drop ID\n",
    "train_X = train_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "train_Y = train_raw['label']\n",
    "test_X = test_raw.drop(['id', 'attack_cat', 'label'], axis=1).select_dtypes(include='number')\n",
    "test_Y = test_raw['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data with min, max of training data\n",
    "test_X1 = (test_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "train_X1 = (train_X - train_X.min(axis=0)) / (train_X.max(axis=0) - train_X.min(axis=0))\n",
    "\n",
    "test_X1[test_X1 < 0] = 0\n",
    "test_X1[test_X1 > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, RFECV, SequentialFeatureSelector, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 1 worse feature iteratively with chi2, ANOVA, mutual info\n",
    "\n",
    "subset_all = []\n",
    "selector = SelectKBest(mutual_info_classif, k=train_X1.shape[1])\n",
    "selector.fit(train_X1, train_Y)\n",
    "sort_index = np.argsort(selector.scores_)\n",
    "cols = train_X1.columns[sort_index]\n",
    "subset_all.append(cols)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 1 worst feature iteratively with SFS, using RF, LR\n",
    "cols = []\n",
    "model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "selector = SequentialFeatureSelector(model, n_features_to_select=1, direction='backward', scoring='f1', cv=5, n_jobs=-1)\n",
    "for k in trange(train_X1.shape[1]-1):\n",
    "    selector.fit(train_X1.drop(cols, axis=1), train_Y)\n",
    "    f = train_X1.columns.drop(cols)[selector.get_support()]\n",
    "    cols.append(f[0])\n",
    "cols.append(train_X1.columns.drop(cols)[0])\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_all.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 1 worst feature iteratively with SFS, using RF, LR\n",
    "model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "selector = RFECV(model, min_features_to_select=train_X1.shape[1], scoring='f1', cv=5, n_jobs=-1)\n",
    "selector.fit(train_X1, train_Y)\n",
    "sort_index = np.argsort(selector.cv_results_.mean_test_score)\n",
    "cols = train_X1.columns[sort_index]\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_all.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "cols = []\n",
    "train_X2 = train_X1.copy()\n",
    "for k in trange(train_X1.shape[1]-1):\n",
    "    model.fit(train_X2, train_Y)\n",
    "    sort_index = np.argsort(model.feature_importances_)\n",
    "    f = train_X1.columns[sort_index[0]]\n",
    "    cols.append(f)\n",
    "    train_X2 = train_X2.drop([f], axis=1)\n",
    "cols.append(train_X1.columns.drop(cols)[0])\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure performance by cv(f1 score)\n",
    "cv_times_all = []\n",
    "f1_all = []\n",
    "model = LogisticRegression(max_iter=10000, random_state=0, n_jobs=-1)\n",
    "for i in range(len(subset_all)):\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        # cross validation\n",
    "        second = time.time()\n",
    "        cv = cross_val_score(model, train_X1[subset_all[i][:k+1]], train_Y, scoring='f1', n_jobs=-1)\n",
    "        second2 = time.time()\n",
    "        cv_times.append(second2 - second)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "    \n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['mi', 'sbs(rf)', 'rfe(rf)', 'im(rf)']\n",
    "pd.DataFrame(cv_times_all, index=methods).to_csv('../Results/Paper/Time_LR.csv')\n",
    "pd.DataFrame(f1_all, index=methods).to_csv('../Results/Paper/F1_LR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Logistic Regression', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[1,:,0], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[2,:,0], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[3,:,0], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[1], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[2], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[3], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=0)\n",
    "for i in range(len(subset_all)):\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        # cross validation\n",
    "        second = time.time()\n",
    "        cv = cross_val_score(model, train_X1[subset_all[i][:k+1]], train_Y, scoring='f1', n_jobs=-1)\n",
    "        second2 = time.time()\n",
    "        cv_times.append(second2 - second)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "    \n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all, index=methods).to_csv('../Results/Paper/Time_GB.csv')\n",
    "pd.DataFrame(f1_all, index=methods).to_csv('../Results/Paper/F1_GB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on Gradient Boosting', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[1,:,0], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[2,:,0], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[3,:,0], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[1], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[2], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[3], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential, layers, optimizers, losses, metrics, callbacks\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCreate(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_times_all = []\n",
    "f1_all = []\n",
    "\n",
    "kf = StratifiedKFold(shuffle=True, random_state=0)\n",
    "callback = callbacks.EarlyStopping(patience=3, min_delta=0.1, restore_best_weights=True)\n",
    "for i in range(len(subset_all)):\n",
    "    cv_times = []\n",
    "    f1s = []\n",
    "    for k in trange(train_X1.shape[1]):\n",
    "        model = ModelCreate((k+1,))\n",
    "        # cross validation\n",
    "        j = 0\n",
    "        cv_time = 0\n",
    "        cv = np.zeros(shape=5)\n",
    "        train_X2 = train_X1[subset_all[i][:k+1]].copy()\n",
    "        for train_index, test_index in kf.split(train_X2, train_Y):\n",
    "            x_train_fold, x_test_fold = train_X2.iloc[train_index, :], train_X2.iloc[test_index, :]\n",
    "            y_train_fold, y_test_fold = train_Y.iloc[train_index], train_Y.iloc[test_index]\n",
    "\n",
    "            second = time.time()\n",
    "            model.fit(x_train_fold.values, y_train_fold.values, validation_data=(x_test_fold, y_test_fold), epochs=30, callbacks=[callback], use_multiprocessing=True, verbose=0)\n",
    "            predict = model.predict(x_test_fold, use_multiprocessing=True)\n",
    "            predict = np.where(predict < 0.5, 0, 1)\n",
    "            cv[j] = f1_score(y_test_fold, predict)\n",
    "            second2 = time.time()\n",
    "            cv_time += second2 - second\n",
    "            j += 1\n",
    "        cv_times.append(cv_time)\n",
    "        f1s.append((cv.mean(), cv.std()))\n",
    "    \n",
    "    cv_times_all.append(cv_times)\n",
    "    f1_all.append(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_times_all, index=methods).to_csv('../Results/Paper/Time_DNN.csv')\n",
    "pd.DataFrame(f1_all, index=methods).to_csv('../Results/Paper/F1_DNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = []\n",
    "fig, axis = plt.subplots(1, 2, figsize=(12, 9))\n",
    "\n",
    "plt.title('F1 Score and Time over number of features on DNN', loc='center')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim((0, 1))\n",
    "\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[0,:,0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[1,:,0], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[2,:,0], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1]), np.array(f1_all)[3,:,0], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[0], color='blue', linestyle='-', label=methods[0])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[1], color='red', linestyle='-', label=methods[1])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[2], color='black', linestyle='-', label=methods[2])\n",
    "plt.plot(range(train_X1.shape[1]), cv_times_all[3], color='cyan', linestyle='-', label=methods[3])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c4f194b091935ea0535537ef7f3ca3b8fc985a0d71c01646ea70346d6ccae7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
